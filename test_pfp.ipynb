{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4277047, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>aspect</th>\n",
       "      <th>GO_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0110165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0043226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID              aspect     GO_term\n",
       "0     P91124  cellular_component  GO:0005575\n",
       "1     P91124  cellular_component  GO:0110165\n",
       "2     P91124  cellular_component  GO:0005737\n",
       "3     P91124  cellular_component  GO:0005622\n",
       "4     P91124  cellular_component  GO:0043226"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(data_dir+'train_set.tsv', delimiter='\\t')\n",
    "print(train_set.shape)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Protein_ID\n",
       "Q02248    494\n",
       "P05067    449\n",
       "P31749    443\n",
       "Q62226    438\n",
       "P01137    428\n",
       "         ... \n",
       "P06436      2\n",
       "P16011      2\n",
       "P68930      2\n",
       "P42487      2\n",
       "O49139      2\n",
       "Name: GO_term, Length: 123969, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('Protein_ID').count()['GO_term'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GO_term\n",
       "GO:0005575    84638\n",
       "GO:0110165    83893\n",
       "GO:0008150    83064\n",
       "GO:0005622    67293\n",
       "GO:0043226    58004\n",
       "              ...  \n",
       "GO:0015038       49\n",
       "GO:0042169       49\n",
       "GO:0016894       48\n",
       "GO:0140463       48\n",
       "GO:0005160       48\n",
       "Name: Protein_ID, Length: 3004, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('GO_term').count()['Protein_ID'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>GO_term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biological_process</th>\n",
       "      <td>2634883</td>\n",
       "      <td>2634883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cellular_component</th>\n",
       "      <td>1109632</td>\n",
       "      <td>1109632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_function</th>\n",
       "      <td>532532</td>\n",
       "      <td>532532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Protein_ID  GO_term\n",
       "aspect                                 \n",
       "biological_process     2634883  2634883\n",
       "cellular_component     1109632  1109632\n",
       "molecular_function      532532   532532"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('aspect').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>aspect</th>\n",
       "      <th>GO_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0110165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0043226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID              aspect     GO_term\n",
       "0     P91124  cellular_component  GO:0005575\n",
       "1     P91124  cellular_component  GO:0110165\n",
       "2     P91124  cellular_component  GO:0005737\n",
       "3     P91124  cellular_component  GO:0005622\n",
       "4     P91124  cellular_component  GO:0043226"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>GO_term</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aspect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biological_process</th>\n",
       "      <td>83064</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cellular_component</th>\n",
       "      <td>84638</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>molecular_function</th>\n",
       "      <td>55698</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Protein_ID  GO_term\n",
       "aspect                                 \n",
       "biological_process       83064     1487\n",
       "cellular_component       84638      678\n",
       "molecular_function       55698      839"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('aspect').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set['GO_term'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123969, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P91124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q55DL5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O81027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q04418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q8IXT2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID\n",
       "0     P91124\n",
       "1     Q55DL5\n",
       "2     O81027\n",
       "3     Q04418\n",
       "4     Q8IXT2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_df = pd.read_csv(data_dir+'train_ids.txt',header = None)\n",
    "train_ids_df.columns = ['Protein_ID']\n",
    "print(train_ids_df.shape)\n",
    "train_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123969, 1024)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_1015</th>\n",
       "      <th>Column_1016</th>\n",
       "      <th>Column_1017</th>\n",
       "      <th>Column_1018</th>\n",
       "      <th>Column_1019</th>\n",
       "      <th>Column_1020</th>\n",
       "      <th>Column_1021</th>\n",
       "      <th>Column_1022</th>\n",
       "      <th>Column_1023</th>\n",
       "      <th>Column_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068176</td>\n",
       "      <td>-0.046478</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>-0.008583</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.046265</td>\n",
       "      <td>-0.059662</td>\n",
       "      <td>-0.050385</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.013138</td>\n",
       "      <td>-0.049591</td>\n",
       "      <td>-0.101074</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.034760</td>\n",
       "      <td>-0.031006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.016434</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.073425</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>-0.040375</td>\n",
       "      <td>-0.093811</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>0.025497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-0.033325</td>\n",
       "      <td>-0.031342</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>-0.032959</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.029907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.025589</td>\n",
       "      <td>-0.011749</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>-0.016266</td>\n",
       "      <td>-0.034973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>-0.049713</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.006241</td>\n",
       "      <td>-0.039703</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>-0.004288</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>-0.033569</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.022186</td>\n",
       "      <td>-0.083862</td>\n",
       "      <td>-0.003841</td>\n",
       "      <td>-0.018631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053589</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.069458</td>\n",
       "      <td>0.042206</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>-0.025436</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.099121</td>\n",
       "      <td>0.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049316</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.108643</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>-0.051056</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>-0.042084</td>\n",
       "      <td>-0.154053</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100647</td>\n",
       "      <td>-0.063293</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>-0.104675</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.047485</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>-0.036774</td>\n",
       "      <td>0.103577</td>\n",
       "      <td>0.005245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  Column_7  \\\n",
       "0  0.068176 -0.046478  0.001752 -0.008583  0.003763  0.046265 -0.059662   \n",
       "1 -0.016434 -0.001583  0.003889  0.073425  0.012428  0.028168 -0.040375   \n",
       "2  0.007904  0.087708 -0.001715  0.037659  0.017883  0.025589 -0.011749   \n",
       "3  0.002447  0.007053  0.064453  0.007271 -0.033569 -0.009933 -0.022186   \n",
       "4  0.049316  0.020691  0.108643  0.016342 -0.051056 -0.017334 -0.042084   \n",
       "\n",
       "   Column_8  Column_9  Column_10  ...  Column_1015  Column_1016  Column_1017  \\\n",
       "0 -0.050385 -0.005173   0.008865  ...    -0.040771    -0.013138    -0.049591   \n",
       "1 -0.093811 -0.017807   0.025497  ...     0.011879    -0.033325    -0.031342   \n",
       "2 -0.084717 -0.016266  -0.034973  ...     0.004829    -0.049713    -0.027176   \n",
       "3 -0.083862 -0.003841  -0.018631  ...    -0.053589    -0.002508    -0.016647   \n",
       "4 -0.154053  0.007347   0.029907  ...    -0.100647    -0.063293     0.002346   \n",
       "\n",
       "   Column_1018  Column_1019  Column_1020  Column_1021  Column_1022  \\\n",
       "0    -0.101074     0.066406     0.008980    -0.003506    -0.024612   \n",
       "1    -0.005245     0.014732     0.081970     0.017456    -0.032959   \n",
       "2    -0.037415    -0.006241    -0.039703     0.001784     0.004719   \n",
       "3    -0.069458     0.042206    -0.051758    -0.025436     0.057373   \n",
       "4    -0.104675    -0.000757    -0.047485     0.003002    -0.036774   \n",
       "\n",
       "   Column_1023  Column_1024  \n",
       "0     0.034760    -0.031006  \n",
       "1     0.053192     0.029907  \n",
       "2    -0.004288     0.001847  \n",
       "3     0.099121     0.032898  \n",
       "4     0.103577     0.005245  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train_embeddings.h5 containing the prott5 embeddings\n",
    "\n",
    "train_embeddings = []\n",
    "protein_ids = []\n",
    "\n",
    "with h5py.File(data_dir+'train_embeddings.h5', 'r') as f:\n",
    "    for protein_id in f.keys():  # protein ids\n",
    "        embeddings = f[protein_id][:]\n",
    "        train_embeddings.append(embeddings)\n",
    "        protein_ids.append(protein_id)\n",
    "\n",
    "# Convert the list of embeddings to a numpy array\n",
    "prott5_embeddings = np.array(train_embeddings)\n",
    "\n",
    "# Create a DataFrame from the embeddings array\n",
    "column_num = prott5_embeddings.shape[1]\n",
    "train_df = pd.DataFrame(prott5_embeddings, columns=[\"Column_\" + str(i) for i in range(1, column_num + 1)])\n",
    "\n",
    "# Set protein_ids as the index of the DataFrame\n",
    "#train_df.index = protein_ids\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P91124',\n",
       " 'Q55DL5',\n",
       " 'O81027',\n",
       " 'Q04418',\n",
       " 'Q7ZT12',\n",
       " 'Q07627',\n",
       " 'Q03370',\n",
       " 'Q9M647',\n",
       " 'B1AMW7',\n",
       " 'A1Z840',\n",
       " 'Q05595',\n",
       " 'P9WLA1',\n",
       " 'P30041',\n",
       " 'Q9Y0Y5',\n",
       " 'Q96DV4',\n",
       " 'P0C342',\n",
       " 'P54144',\n",
       " 'Q8R2Z3',\n",
       " 'Q9VEX1',\n",
       " 'Q9UYD1',\n",
       " 'Q13287',\n",
       " 'A0A2R8YGX0',\n",
       " 'Q9UUI3',\n",
       " 'Q57ZS4',\n",
       " 'Q06496',\n",
       " 'Q387U0',\n",
       " 'Q8VYE2',\n",
       " 'P45879',\n",
       " 'Q5RL73',\n",
       " 'C9JQU7',\n",
       " 'P40616',\n",
       " 'Q6MZP7',\n",
       " 'O08700',\n",
       " 'Q9SUV1',\n",
       " 'Q8N661',\n",
       " 'F4J5N9',\n",
       " 'Q99720',\n",
       " 'Q86XP1',\n",
       " 'Q9Z0I9',\n",
       " 'P51427',\n",
       " 'Q969Z0',\n",
       " 'Q12117',\n",
       " 'B7Z0K2',\n",
       " 'C6KSN5',\n",
       " 'P56971',\n",
       " 'A0A7I2V594',\n",
       " 'Q54JT7',\n",
       " 'Q38BM5',\n",
       " 'G5EE70',\n",
       " 'Q8SXA8',\n",
       " 'O62531',\n",
       " 'Q02375',\n",
       " 'Q8VYN9',\n",
       " 'Q9H8V3',\n",
       " 'P33891',\n",
       " 'D2Y5Q2',\n",
       " 'A2A2V1',\n",
       " 'Q9VUF8',\n",
       " 'P40031',\n",
       " 'Q9BXY0',\n",
       " 'Q9ESD1',\n",
       " 'P78344',\n",
       " 'Q9JM54',\n",
       " 'P28331',\n",
       " 'P39683',\n",
       " 'P35577',\n",
       " 'P76090',\n",
       " 'A0A0A0MQW1',\n",
       " 'Q5UCC4',\n",
       " 'Q5W0B1',\n",
       " 'Q3EC77',\n",
       " 'Q6A332',\n",
       " 'A0A6Q8PFQ9',\n",
       " 'C9JRZ8',\n",
       " 'Q15007',\n",
       " 'Q5XJA3',\n",
       " 'Q9SRB0',\n",
       " 'Q21966',\n",
       " 'Q96IL0',\n",
       " 'P63027',\n",
       " 'P55850',\n",
       " 'Q583J9',\n",
       " 'A0A0A0MS29',\n",
       " 'E5RFP0',\n",
       " 'Q9VF10',\n",
       " 'O14359',\n",
       " 'Q9LZB8',\n",
       " 'A0A1D8PGT0',\n",
       " 'C0LGG7',\n",
       " 'Q4TTV4',\n",
       " 'Q96PU8',\n",
       " 'E9Q6H8',\n",
       " 'E9PI18',\n",
       " 'Q10F03',\n",
       " 'Q17868',\n",
       " 'Q8C1F4',\n",
       " 'Q9H9A5',\n",
       " 'Q6DGA8',\n",
       " 'Q5AMT2',\n",
       " 'Q38AJ6',\n",
       " 'D4YW53',\n",
       " 'P38285',\n",
       " 'Q91Z96',\n",
       " 'P62820',\n",
       " 'Q9DD06',\n",
       " 'P01579',\n",
       " 'Q61136',\n",
       " 'F4IBS8',\n",
       " 'Q4GYY0',\n",
       " 'A0A384MTQ3',\n",
       " 'P0C420',\n",
       " 'Q5BJ56',\n",
       " 'Q8VZS7',\n",
       " 'Q9VRU2',\n",
       " 'Q90ZM5',\n",
       " 'Q95YI5',\n",
       " 'Q8WX93',\n",
       " 'Q9ZSJ0',\n",
       " 'O74325',\n",
       " 'Q9FH16',\n",
       " 'Q9M2U3',\n",
       " 'O13878',\n",
       " 'Q8IRM6',\n",
       " 'P11217',\n",
       " 'Q9H0R8',\n",
       " 'A0A0S2Z5V5',\n",
       " 'Q57ZA0',\n",
       " 'Q13335',\n",
       " 'Q5T457',\n",
       " 'Q2NL82',\n",
       " 'A0A7G6J4N4',\n",
       " 'Q5LJQ4',\n",
       " 'O96378',\n",
       " 'Q53FM2',\n",
       " 'Q38BK3',\n",
       " 'O88685',\n",
       " 'A8DYH2',\n",
       " 'Q99189',\n",
       " 'P56564',\n",
       " 'O13689',\n",
       " 'P9WNZ5',\n",
       " 'Q2F6K0',\n",
       " 'Q94527',\n",
       " 'Q9P6N3',\n",
       " 'Q3UR78',\n",
       " 'O43679',\n",
       " 'Q9VJU5',\n",
       " 'Q8HCN4',\n",
       " 'Q8BVZ1',\n",
       " 'C9K0M0',\n",
       " 'A0A0G2K850',\n",
       " 'G5EFY1',\n",
       " 'P15515',\n",
       " 'C9D7D0',\n",
       " 'Q9HDU2',\n",
       " 'Q09131',\n",
       " 'A0A7P0T843',\n",
       " 'P05511',\n",
       " 'P9WGR1',\n",
       " 'Q86B77',\n",
       " 'Q99L04',\n",
       " 'Q14626',\n",
       " 'F2Z3L2',\n",
       " 'Q9CAL2',\n",
       " 'J9VT45',\n",
       " 'Q9H0A6',\n",
       " 'P41216',\n",
       " 'P10412',\n",
       " 'Q7JPR9',\n",
       " 'P53405',\n",
       " 'Q86VP3',\n",
       " 'Q64267',\n",
       " 'F8W8Z9',\n",
       " 'Q7L5A3',\n",
       " 'D3YTF8',\n",
       " 'O74700',\n",
       " 'O42254',\n",
       " 'Q9Y230',\n",
       " 'A8K517',\n",
       " 'Q8IUH3',\n",
       " 'Q9UTB3',\n",
       " 'C9JEM7',\n",
       " 'Q06624',\n",
       " 'P25558',\n",
       " 'G8BID5',\n",
       " 'Q5T5C0',\n",
       " 'O04573',\n",
       " 'Q5B5Z6',\n",
       " 'F4I5D5',\n",
       " 'Q5QPE5',\n",
       " 'I3L383',\n",
       " 'O35795',\n",
       " 'Q580W3',\n",
       " 'Q6PFR5',\n",
       " 'Q6X4A1',\n",
       " 'P40565',\n",
       " 'P26647',\n",
       " 'H7C5E4',\n",
       " 'Q0WPF2',\n",
       " 'A7MBH5',\n",
       " 'P9WNA7',\n",
       " 'Q9W2S1',\n",
       " 'A0A6Q8PFH6',\n",
       " 'P42222',\n",
       " 'Q38BU5',\n",
       " 'P04441',\n",
       " 'C9JWV4',\n",
       " 'P43256',\n",
       " 'Q8C3Q5',\n",
       " 'Q86WX3',\n",
       " 'Q9Z2R2',\n",
       " 'E0SC32',\n",
       " 'Q8TDN6',\n",
       " 'Q8T0C2',\n",
       " 'O43684',\n",
       " 'J3QLD1',\n",
       " 'Q3LI73',\n",
       " 'O75840',\n",
       " 'P73091',\n",
       " 'Q12379',\n",
       " 'Q5A1E0',\n",
       " 'H2KY90',\n",
       " 'Q28283',\n",
       " 'B3KX59',\n",
       " 'Q8IMG1',\n",
       " 'Q6AY25',\n",
       " 'A0A087WZG8',\n",
       " 'Q8LF21',\n",
       " 'Q55GV3',\n",
       " 'Q967Y4',\n",
       " 'Q9W326',\n",
       " 'P36101',\n",
       " 'Q9CYH2',\n",
       " 'Q9LUS6',\n",
       " 'Q63087',\n",
       " 'P07711',\n",
       " 'Q9WUV6',\n",
       " 'P91668',\n",
       " 'Q57U61',\n",
       " 'Q8HXG5',\n",
       " 'Q8WRE7',\n",
       " 'G5E975',\n",
       " 'O80575',\n",
       " 'Q39080',\n",
       " 'P32644',\n",
       " 'Q9FGQ9',\n",
       " 'P07828',\n",
       " 'Q57ZD2',\n",
       " 'Q584L0',\n",
       " 'Q94A08',\n",
       " 'Q9CAM1',\n",
       " 'X6R4A7',\n",
       " 'Q24326',\n",
       " 'O15393',\n",
       " 'A0A6I8PRV1',\n",
       " 'A1YK36',\n",
       " 'Q9SUI6',\n",
       " 'Q9C8J7',\n",
       " 'Q9XWU8',\n",
       " 'A0A1B0GT25',\n",
       " 'Q86UA6',\n",
       " 'P48526',\n",
       " 'Q53EU6',\n",
       " 'Q06104',\n",
       " 'Q389W4',\n",
       " 'Q04174',\n",
       " 'Q9VU15',\n",
       " 'A2BG85',\n",
       " 'Q95U83',\n",
       " 'Q9FKM2',\n",
       " 'Q9M314',\n",
       " 'P29477',\n",
       " 'Q35315',\n",
       " 'Q9LUS2',\n",
       " 'Q9Y6K9',\n",
       " 'Q5XF03',\n",
       " 'P41000',\n",
       " 'Q5AFN8',\n",
       " 'Q5VX58',\n",
       " 'Q59T87',\n",
       " 'Q32KD2',\n",
       " 'Q9BZI7',\n",
       " 'Q920B6',\n",
       " 'P52569',\n",
       " 'P56857',\n",
       " 'P10927',\n",
       " 'J3QLJ5',\n",
       " 'Q9VI63',\n",
       " 'Q99JV1',\n",
       " 'P54121',\n",
       " 'Q10085',\n",
       " 'P48008',\n",
       " 'Q06710',\n",
       " 'A0A384NL00',\n",
       " 'P53335',\n",
       " 'Q64368',\n",
       " 'Q57Z07',\n",
       " 'A0A1D8PJ31',\n",
       " 'Q5EBL8',\n",
       " 'Q9Z307',\n",
       " 'Q9M266',\n",
       " 'A1L4Q0',\n",
       " 'Q9BYN8',\n",
       " 'Q5SRR4',\n",
       " 'Q91YR5',\n",
       " 'Q9UPN7',\n",
       " 'A0A384ME24',\n",
       " 'Q8T6L9',\n",
       " 'Q59FH4',\n",
       " 'P28222',\n",
       " 'Q9C8K2',\n",
       " 'A6HMM2',\n",
       " 'Q9ER63',\n",
       " 'Q9NZ72',\n",
       " 'Q01538',\n",
       " 'Q06839',\n",
       " 'Q9SD71',\n",
       " 'E9PY03',\n",
       " 'Q38CZ2',\n",
       " 'Q8RWN7',\n",
       " 'Q388D7',\n",
       " 'A0A343URW6',\n",
       " 'P05744',\n",
       " 'Q59IW8',\n",
       " 'B0V1I9',\n",
       " 'P75089',\n",
       " 'P03170',\n",
       " 'Q95T63',\n",
       " 'Q8N163',\n",
       " 'Q00266',\n",
       " 'Q60787',\n",
       " 'C9JYB8',\n",
       " 'P9WHT1',\n",
       " 'Q8BH04',\n",
       " 'Q9VNF6',\n",
       " 'Q12280',\n",
       " 'Q3URU2',\n",
       " 'Q9HBI6',\n",
       " 'Q8III2',\n",
       " 'Q38EY4',\n",
       " 'A0A0B4KF97',\n",
       " 'H2KYA4',\n",
       " 'F2Z2I2',\n",
       " 'A0A7P0TBK2',\n",
       " 'Q06541',\n",
       " 'M9NEH9',\n",
       " 'A0A0B4K669',\n",
       " 'P60570',\n",
       " 'P32621',\n",
       " 'K4C9E2',\n",
       " 'Q6EN94',\n",
       " 'Q8L910',\n",
       " 'P14956',\n",
       " 'Q52KI8',\n",
       " 'P30740',\n",
       " 'A7MBP4',\n",
       " 'Q86I44',\n",
       " 'Q8IFJ4',\n",
       " 'Q3ZT31',\n",
       " 'Q7KU86',\n",
       " 'L0R6P0',\n",
       " 'Q8IK27',\n",
       " 'F4JRE0',\n",
       " 'O00273',\n",
       " 'Q5R3F8',\n",
       " 'Q12519',\n",
       " 'Q5M7U6',\n",
       " 'Q16563',\n",
       " 'Q7LGC8',\n",
       " 'O95476',\n",
       " 'Q86SS6',\n",
       " 'Q8TES7',\n",
       " 'Q5W0Z9',\n",
       " 'P29120',\n",
       " 'Q8CIE6',\n",
       " 'Q381J3',\n",
       " 'A0A8I6A9B1',\n",
       " 'Q2W8S0',\n",
       " 'A0A0A0MRW6',\n",
       " 'P23396',\n",
       " 'A0A1U9X845',\n",
       " 'Q385K8',\n",
       " 'P06781',\n",
       " 'E5KMK7',\n",
       " 'A1Z7H2',\n",
       " 'P42632',\n",
       " 'Q92781',\n",
       " 'Q8I5P0',\n",
       " 'P21238',\n",
       " 'Q5AS72',\n",
       " 'O88828',\n",
       " 'Q9ULL4',\n",
       " 'Q9W3X7',\n",
       " 'Q9BSQ5',\n",
       " 'P14893',\n",
       " 'Q6AWH4',\n",
       " 'Q9P2D0',\n",
       " 'E5KN95',\n",
       " 'Q9U405',\n",
       " 'O53505',\n",
       " 'Q944G8',\n",
       " 'P17078',\n",
       " 'Q9LYK2',\n",
       " 'C0LU16',\n",
       " 'Q61151',\n",
       " 'Q9NZH0',\n",
       " 'Q08822',\n",
       " 'P14679',\n",
       " 'P78543',\n",
       " 'P17014',\n",
       " 'Q8IDR4',\n",
       " 'Q7Z589',\n",
       " 'Q9W0G1',\n",
       " 'Q57Y49',\n",
       " 'Q9BXF6',\n",
       " 'Q8WV44',\n",
       " 'A0A021WW32',\n",
       " 'Q9NZ81',\n",
       " 'Q0R5T2',\n",
       " 'Q9LF33',\n",
       " 'O74540',\n",
       " 'P01742',\n",
       " 'Q385D3',\n",
       " 'Q381P9',\n",
       " 'Q8BZ32',\n",
       " 'P07998',\n",
       " 'F4HZG9',\n",
       " 'Q9AWB2',\n",
       " 'O74923',\n",
       " 'O75354',\n",
       " 'D3ZUQ0',\n",
       " 'P26686',\n",
       " 'Q9VM02',\n",
       " 'P49227',\n",
       " 'K7ENA1',\n",
       " 'Q9FE79',\n",
       " 'G3UXN8',\n",
       " 'P9WLH3',\n",
       " 'Q9P3W1',\n",
       " 'Q53H47',\n",
       " 'I1MRZ6',\n",
       " 'Q99965',\n",
       " 'P16033',\n",
       " 'R4GN98',\n",
       " 'O45717',\n",
       " 'H7C4S4',\n",
       " 'P39173',\n",
       " 'Q01151',\n",
       " 'O42968',\n",
       " 'F8W785',\n",
       " 'O14197',\n",
       " 'Q06451',\n",
       " 'A4GG66',\n",
       " 'Q8TD43',\n",
       " 'I3L3U8',\n",
       " 'Q9C002',\n",
       " 'H0YK48',\n",
       " 'O43182',\n",
       " 'P39706',\n",
       " 'P39749',\n",
       " 'Q86B59',\n",
       " 'H3BN14',\n",
       " 'Q9S9P8',\n",
       " 'Q57VF7',\n",
       " 'Q8TBB6',\n",
       " 'Q13886',\n",
       " 'P30149',\n",
       " 'Q38CI8',\n",
       " 'C1BH42',\n",
       " 'A0A804HLH2',\n",
       " 'Q8N682',\n",
       " 'Q5AKU5',\n",
       " 'P49693',\n",
       " 'Q6IBV1',\n",
       " 'F8W9U3',\n",
       " 'Q54S82',\n",
       " 'Q86LT0',\n",
       " 'Q39002',\n",
       " 'Q95PA9',\n",
       " 'Q389Q1',\n",
       " 'Q38F93',\n",
       " 'Q9ZQ18',\n",
       " 'Q9SHJ5',\n",
       " 'A2VD39',\n",
       " 'P43297',\n",
       " 'A0A8I5ZZH4',\n",
       " 'P29966',\n",
       " 'Q62814',\n",
       " 'G5E9A6',\n",
       " 'P0ACF0',\n",
       " 'Q8S950',\n",
       " 'X1WH68',\n",
       " 'O44191',\n",
       " 'O60163',\n",
       " 'Q9FVQ1',\n",
       " 'P18962',\n",
       " 'Q8I6U2',\n",
       " 'Q9H329',\n",
       " 'C6KSL4',\n",
       " 'Q99689',\n",
       " 'O42894',\n",
       " 'Q9R1P1',\n",
       " 'Q8VYL1',\n",
       " 'A4IJ41',\n",
       " 'P9WMP5',\n",
       " 'P9WHU1',\n",
       " 'D3U716',\n",
       " 'Q7L3S4',\n",
       " 'Q6PST4',\n",
       " 'A0A0C4DG26',\n",
       " 'Q12467',\n",
       " 'B9A067',\n",
       " 'Q96289',\n",
       " 'Q9H6F5',\n",
       " 'Q7Z417',\n",
       " 'O05456',\n",
       " 'Q385I2',\n",
       " 'Q6FY51',\n",
       " 'Q59DN9',\n",
       " 'O23712',\n",
       " 'Q8IK32',\n",
       " 'Q9Y806',\n",
       " 'O09159',\n",
       " 'Q94AU2',\n",
       " 'Q92734',\n",
       " 'P62073',\n",
       " 'Q8K0E8',\n",
       " 'O14280',\n",
       " 'A0A804HI47',\n",
       " 'Q9D808',\n",
       " 'Q8L5Y6',\n",
       " 'B0BNM2',\n",
       " 'Q5ZUV9',\n",
       " 'Q9LJ04',\n",
       " 'Q9JHF3',\n",
       " 'H3BQ76',\n",
       " 'Q86T65',\n",
       " 'P35442',\n",
       " 'Q9Y703',\n",
       " 'P35318',\n",
       " 'Q63811',\n",
       " 'O64883',\n",
       " 'Q8RY25',\n",
       " 'P0DTU4',\n",
       " 'B7U540',\n",
       " 'H0YML5',\n",
       " 'Q57UR4',\n",
       " 'A0A8I6AFP0',\n",
       " 'B4DZU5',\n",
       " 'O14261',\n",
       " 'Q9XWQ1',\n",
       " 'Q96AP4',\n",
       " 'Q383P0',\n",
       " 'F4JS93',\n",
       " 'Q9WU31',\n",
       " 'Q06053',\n",
       " 'P0C054',\n",
       " 'P36097',\n",
       " 'Q8N5H7',\n",
       " 'Q9P6K9',\n",
       " 'Q9ZSJ6',\n",
       " 'Q5APD4',\n",
       " 'P39735',\n",
       " 'O13318',\n",
       " 'P12684',\n",
       " 'O18229',\n",
       " 'Q2F962',\n",
       " 'M9PBJ9',\n",
       " 'Q16586',\n",
       " 'P54278',\n",
       " 'Q583H0',\n",
       " 'P0AER0',\n",
       " 'Q80WW9',\n",
       " 'Q15561',\n",
       " 'Q57UU7',\n",
       " 'P07954',\n",
       " 'Q8IJ11',\n",
       " 'P36877',\n",
       " 'Q95T18',\n",
       " 'P29965',\n",
       " 'Q8N0B4',\n",
       " 'Q9P7X0',\n",
       " 'P39196',\n",
       " 'Q9WV71',\n",
       " 'E9PV24',\n",
       " 'Q8VC74',\n",
       " 'F4IQ10',\n",
       " 'B6JXN5',\n",
       " 'Q9NZU1',\n",
       " 'P62315',\n",
       " 'Q08639',\n",
       " 'Q1ZXL0',\n",
       " 'O00746',\n",
       " 'Q57XJ4',\n",
       " 'P07174',\n",
       " 'Q9CWP8',\n",
       " 'O80434',\n",
       " 'Q96T76',\n",
       " 'Q9UUM2',\n",
       " 'P31939',\n",
       " 'Q8WV37',\n",
       " 'Q9ER58',\n",
       " 'Q9LXB3',\n",
       " 'Q9HBF4',\n",
       " 'J9VI91',\n",
       " 'Q5AEM8',\n",
       " 'Q9VFS1',\n",
       " 'Q9LFF7',\n",
       " 'Q96CM3',\n",
       " 'Q6FY13',\n",
       " 'Q07821',\n",
       " 'Q5JW30',\n",
       " 'Q99M04',\n",
       " 'Q68FE2',\n",
       " 'Q38AV7',\n",
       " 'P55317',\n",
       " 'P32561',\n",
       " 'A0A140VK08',\n",
       " 'A0A0K3AR81',\n",
       " 'Q76NU3',\n",
       " 'F7EUL0',\n",
       " 'Q967R7',\n",
       " 'Q95QG4',\n",
       " 'Q582N6',\n",
       " 'Q5F1R6',\n",
       " 'Q8T9L5',\n",
       " 'E9PFG7',\n",
       " 'P79135',\n",
       " 'P02786',\n",
       " 'Q08873',\n",
       " 'Q9SW96',\n",
       " 'A0A0B4KHC8',\n",
       " 'Q6A333',\n",
       " 'Q8UUR2',\n",
       " 'Q9W501',\n",
       " 'Q9LZP8',\n",
       " 'P18122',\n",
       " 'O43678',\n",
       " 'A0A2S1ZR87',\n",
       " 'Q9ZV36',\n",
       " 'P04627',\n",
       " 'Q86U86',\n",
       " 'Q96JW4',\n",
       " 'P54265',\n",
       " 'Q8W4E7',\n",
       " 'Q8LPA2',\n",
       " 'Q09429',\n",
       " 'P37666',\n",
       " 'A8MTJ3',\n",
       " 'Q94EH2',\n",
       " 'Q384C0',\n",
       " 'G3V2V6',\n",
       " 'Q388V9',\n",
       " 'Q6IBL8',\n",
       " 'Q5BAB9',\n",
       " 'P09132',\n",
       " 'A8WH76',\n",
       " 'Q7JMI1',\n",
       " 'O95294',\n",
       " 'P0ABJ6',\n",
       " 'P48610',\n",
       " 'Q9GZC8',\n",
       " 'Q0GXS4',\n",
       " 'Q9NZL8',\n",
       " 'H0YD65',\n",
       " 'Q9V444',\n",
       " 'Q9NTX7',\n",
       " 'Q4WNP9',\n",
       " 'P19526',\n",
       " 'F1R7F0',\n",
       " 'Q8NEY8',\n",
       " 'A0A0S2Z3P9',\n",
       " 'P51817',\n",
       " 'Q6NR17',\n",
       " 'P97305',\n",
       " 'P85171',\n",
       " 'Q9D4B2',\n",
       " 'Q9UK61',\n",
       " 'Q9BUW7',\n",
       " 'Q9XDM6',\n",
       " 'O14057',\n",
       " 'A6NEQ0',\n",
       " 'Q9WVD5',\n",
       " 'P51784',\n",
       " 'P07187',\n",
       " 'Q96S16',\n",
       " 'Q9NPD5',\n",
       " 'O14026',\n",
       " 'Q91ZZ3',\n",
       " 'P02921',\n",
       " 'O75845',\n",
       " 'O88736',\n",
       " 'Q99543',\n",
       " 'Q583A8',\n",
       " 'P0AE30',\n",
       " 'O33203',\n",
       " 'Q6UWI2',\n",
       " 'Q14AK4',\n",
       " 'E9PUL5',\n",
       " 'Q9WUT3',\n",
       " 'Q9P419',\n",
       " 'Q8SWU0',\n",
       " 'P07936',\n",
       " 'Q42139',\n",
       " 'Q8GUG7',\n",
       " 'F4I6M1',\n",
       " 'P62908',\n",
       " 'Q9HTI6',\n",
       " 'Q9UTN9',\n",
       " 'B7Z4J8',\n",
       " 'P53276',\n",
       " 'G3V2N3',\n",
       " 'Q95RQ8',\n",
       " 'Q24537',\n",
       " 'O64733',\n",
       " 'M9PG57',\n",
       " 'Q8TBZ2',\n",
       " 'Q16659',\n",
       " 'A2I2P1',\n",
       " 'A2BFP6',\n",
       " 'P75835',\n",
       " 'A0A3B3IU45',\n",
       " 'Q5GLZ8',\n",
       " 'C4NAP3',\n",
       " 'P53215',\n",
       " 'Q581Y9',\n",
       " 'Q9BRX5',\n",
       " 'Q99PG0',\n",
       " 'Q60596',\n",
       " 'Q6FLR5',\n",
       " 'P30632',\n",
       " 'P29372',\n",
       " 'Q9SIS7',\n",
       " 'P35278',\n",
       " 'Q2GIY3',\n",
       " 'F1SWA3',\n",
       " 'Q5EB91',\n",
       " 'Q8WXI2',\n",
       " 'Q10198',\n",
       " 'Q383K7',\n",
       " 'Q68D86',\n",
       " 'H0YJG0',\n",
       " 'Q2XU92',\n",
       " 'P9WHT9',\n",
       " 'P87318',\n",
       " 'Q9NJE9',\n",
       " 'Q22015',\n",
       " 'P28470',\n",
       " 'Q9HC35',\n",
       " 'Q9Y2G0',\n",
       " 'O16844',\n",
       " 'A0A8I5ZNX4',\n",
       " 'Q9CV60',\n",
       " 'Q9NTK5',\n",
       " 'E9PJV9',\n",
       " 'Q6ZNB7',\n",
       " 'O88339',\n",
       " 'Q8K5A9',\n",
       " 'A8MZH8',\n",
       " 'P14373',\n",
       " 'Q9C037',\n",
       " 'O77238',\n",
       " 'Q3UN04',\n",
       " 'P32901',\n",
       " 'Q5XJL0',\n",
       " 'F1SPZ9',\n",
       " 'P08178',\n",
       " 'Q7LBC6',\n",
       " 'A6KG03',\n",
       " 'O60099',\n",
       " 'Q8RW94',\n",
       " 'Q5AIR7',\n",
       " 'A0A7I2V3Z1',\n",
       " 'Q9JJS0',\n",
       " 'Q3HS82',\n",
       " 'O75208',\n",
       " 'Q9VAJ1',\n",
       " 'P11087',\n",
       " 'Q10275',\n",
       " 'Q9D1H6',\n",
       " 'Q6Z7U5',\n",
       " 'Q01804',\n",
       " 'Q07666',\n",
       " 'Q9XTB2',\n",
       " 'Q9BU19',\n",
       " 'G5EBV3',\n",
       " 'Q9NTU7',\n",
       " 'P06336',\n",
       " 'Q3LI70',\n",
       " 'Q55DR6',\n",
       " 'O75569',\n",
       " 'Q9STX5',\n",
       " 'O17144',\n",
       " 'Q9P4W9',\n",
       " 'P01590',\n",
       " 'Q9W384',\n",
       " 'Q8IM28',\n",
       " 'Q96NB1',\n",
       " 'Q54CH1',\n",
       " 'Q86UV5',\n",
       " 'P60905',\n",
       " 'A0A0S2Z4X1',\n",
       " 'Q9ZQI2',\n",
       " 'M0QX85',\n",
       " 'P64599',\n",
       " 'Q8LCW9',\n",
       " 'D6XEI2',\n",
       " 'P18161',\n",
       " 'P63321',\n",
       " 'Q6P2H3',\n",
       " 'Q10MW6',\n",
       " 'P9WPG7',\n",
       " 'Q2F947',\n",
       " 'Q01992',\n",
       " 'G0RZB3',\n",
       " 'Q384T6',\n",
       " 'P36076',\n",
       " 'Q9S7D8',\n",
       " 'Q54TM7',\n",
       " 'P34021',\n",
       " 'Q96P11',\n",
       " 'Q7KTC5',\n",
       " 'P47100',\n",
       " 'A0A1W2PQP6',\n",
       " 'Q9Y2T5',\n",
       " 'P97817',\n",
       " 'Q9ULU4',\n",
       " 'P25524',\n",
       " 'P79760',\n",
       " 'P68366',\n",
       " 'Q6DBH0',\n",
       " 'Q9N2I8',\n",
       " 'Q9UGM5',\n",
       " 'Q59UP6',\n",
       " 'Q09897',\n",
       " 'Q9FKG5',\n",
       " 'O51148',\n",
       " 'Q06413',\n",
       " 'P9WGK9',\n",
       " 'A0Q7H3',\n",
       " 'Q9R155',\n",
       " 'Q9JL04',\n",
       " 'P47197',\n",
       " 'Q9ZQW0',\n",
       " 'Q8VYS9',\n",
       " 'Q59US5',\n",
       " 'Q57XW0',\n",
       " 'Q09254',\n",
       " 'Q3KR80',\n",
       " 'Q7XDI3',\n",
       " 'P9WI87',\n",
       " 'Q8TBF2',\n",
       " 'Q586I0',\n",
       " 'Q9UUG6',\n",
       " 'B9ENQ3',\n",
       " 'Q9P0L9',\n",
       " 'Q8WYR1',\n",
       " 'Q86WA9',\n",
       " 'O74805',\n",
       " 'Q7TSF0',\n",
       " 'O14713',\n",
       " 'O00159',\n",
       " 'O14003',\n",
       " 'Q9CQN6',\n",
       " 'Q9T0H1',\n",
       " 'Q9BZ67',\n",
       " 'P40567',\n",
       " 'Q74JU6',\n",
       " 'Q9NZM5',\n",
       " 'A6NNZ2',\n",
       " 'P41036',\n",
       " 'O15265',\n",
       " 'Q92989',\n",
       " 'O13838',\n",
       " 'E9PTQ9',\n",
       " 'A6K8N6',\n",
       " 'Q6PJP8',\n",
       " 'P51649',\n",
       " 'Q12122',\n",
       " 'Q9UKY0',\n",
       " 'P38781',\n",
       " 'Q9NCP8',\n",
       " 'O14653',\n",
       " 'Q32L77',\n",
       " 'P49591',\n",
       " 'Q62611',\n",
       " 'P47870',\n",
       " 'Q8LSP3',\n",
       " 'Q9UD71',\n",
       " 'P9WJJ1',\n",
       " 'H0YLC9',\n",
       " 'P51608',\n",
       " 'C6KSR7',\n",
       " 'B1AL79',\n",
       " 'Q9VMM6',\n",
       " 'Q92499',\n",
       " 'Q9Y462',\n",
       " 'Q381I9',\n",
       " 'O18400',\n",
       " 'P40229',\n",
       " 'Q80XF7',\n",
       " 'Q01546',\n",
       " 'P40168',\n",
       " 'Q2F6M6',\n",
       " 'Q385Q5',\n",
       " 'Q9XEX2',\n",
       " 'Q9ULP0',\n",
       " 'Q9BXI2',\n",
       " 'Q08003',\n",
       " 'Q6EIG7',\n",
       " 'Q386D0',\n",
       " 'P35419',\n",
       " 'O75781',\n",
       " 'P9WJZ7',\n",
       " 'Q969Y2',\n",
       " 'P00489',\n",
       " 'P54762',\n",
       " 'Q9FI32',\n",
       " 'F4I854',\n",
       " 'F1SPU1',\n",
       " 'Q8L7R3',\n",
       " 'Q9Z127',\n",
       " 'H0YWU3',\n",
       " 'Q9R1N3',\n",
       " 'P0A9A9',\n",
       " 'P39533',\n",
       " 'Q6NYC1',\n",
       " 'Q9LZM1',\n",
       " 'Q9CZX2',\n",
       " 'P63055',\n",
       " 'O04355',\n",
       " 'Q8IDB6',\n",
       " 'Q8CGV8',\n",
       " 'O01348',\n",
       " 'P69801',\n",
       " 'P52435',\n",
       " 'F1QZU4',\n",
       " 'Q9HCH5',\n",
       " 'B4PZQ4',\n",
       " 'Q8IDR5',\n",
       " 'P9WQF7',\n",
       " 'Q38CD0',\n",
       " 'Q95S72',\n",
       " 'A3KPQ7',\n",
       " 'H8ESE4',\n",
       " 'O59807',\n",
       " 'Q62159',\n",
       " 'Q59MN0',\n",
       " 'B3H7K2',\n",
       " 'Q5B6G6',\n",
       " 'O16242',\n",
       " 'Q59WC6',\n",
       " 'Q9VSW1',\n",
       " 'A1XJ11',\n",
       " 'P19659',\n",
       " 'D4A039',\n",
       " 'Q57W06',\n",
       " 'Q8R0F3',\n",
       " 'Q9XFJ8',\n",
       " 'P83861',\n",
       " 'P33993',\n",
       " 'Q9UNK9',\n",
       " 'Q9USW5',\n",
       " 'Q38AX4',\n",
       " 'A0A0H2US87',\n",
       " 'P47872',\n",
       " 'P42357',\n",
       " 'P32451',\n",
       " 'P59833',\n",
       " 'Q90712',\n",
       " 'P15567',\n",
       " 'X2JJU0',\n",
       " 'Q8TBA6',\n",
       " 'Q385T3',\n",
       " 'Q3U435',\n",
       " 'P48732',\n",
       " 'M9PDB0',\n",
       " 'Q9H040',\n",
       " 'Q584H3',\n",
       " 'Q57VT1',\n",
       " 'Q6FTW6',\n",
       " 'O13709',\n",
       " 'O08775',\n",
       " 'A0A0S1TJ81',\n",
       " 'G5EG78',\n",
       " 'Q8L6Y4',\n",
       " 'Q2F6J8',\n",
       " 'Q8R500',\n",
       " 'P32784',\n",
       " 'Q9NXX6',\n",
       " 'P9WFL3',\n",
       " 'Q86UU9',\n",
       " 'E5RJW1',\n",
       " 'Q9Y296',\n",
       " 'Q47534',\n",
       " 'P15735',\n",
       " 'Q961X2',\n",
       " 'Q9DBA9',\n",
       " 'O35054',\n",
       " 'P48365',\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_id_has_cc = train_set[train_set['aspect'] == 'cellular_component']['Protein_ID'].unique().tolist()\n",
    "prot_id_has_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84638"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prot_id_has_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_embed_df = pd.concat((train_ids_df, train_df), axis=1)\n",
    "cc_train = id_embed_df[id_embed_df['Protein_ID'].isin(prot_id_has_cc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_1015</th>\n",
       "      <th>Column_1016</th>\n",
       "      <th>Column_1017</th>\n",
       "      <th>Column_1018</th>\n",
       "      <th>Column_1019</th>\n",
       "      <th>Column_1020</th>\n",
       "      <th>Column_1021</th>\n",
       "      <th>Column_1022</th>\n",
       "      <th>Column_1023</th>\n",
       "      <th>Column_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P91124</td>\n",
       "      <td>0.068176</td>\n",
       "      <td>-0.046478</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>-0.008583</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.046265</td>\n",
       "      <td>-0.059662</td>\n",
       "      <td>-0.050385</td>\n",
       "      <td>-0.005173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040771</td>\n",
       "      <td>-0.013138</td>\n",
       "      <td>-0.049591</td>\n",
       "      <td>-0.101074</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.008980</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.034760</td>\n",
       "      <td>-0.031006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q55DL5</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.073425</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>-0.040375</td>\n",
       "      <td>-0.093811</td>\n",
       "      <td>-0.017807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-0.033325</td>\n",
       "      <td>-0.031342</td>\n",
       "      <td>-0.005245</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>0.081970</td>\n",
       "      <td>0.017456</td>\n",
       "      <td>-0.032959</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.029907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O81027</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>0.025589</td>\n",
       "      <td>-0.011749</td>\n",
       "      <td>-0.084717</td>\n",
       "      <td>-0.016266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>-0.049713</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.037415</td>\n",
       "      <td>-0.006241</td>\n",
       "      <td>-0.039703</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>-0.004288</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q04418</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>-0.033569</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>-0.022186</td>\n",
       "      <td>-0.083862</td>\n",
       "      <td>-0.003841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053589</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>-0.069458</td>\n",
       "      <td>0.042206</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>-0.025436</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.099121</td>\n",
       "      <td>0.032898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q7ZT12</td>\n",
       "      <td>0.056488</td>\n",
       "      <td>0.019241</td>\n",
       "      <td>0.112122</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-0.055939</td>\n",
       "      <td>-0.016129</td>\n",
       "      <td>-0.045105</td>\n",
       "      <td>-0.152466</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096985</td>\n",
       "      <td>-0.064880</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>-0.106934</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>-0.051544</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>-0.038788</td>\n",
       "      <td>0.106018</td>\n",
       "      <td>0.013321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123964</th>\n",
       "      <td>Q8LE52</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>-0.062469</td>\n",
       "      <td>0.046478</td>\n",
       "      <td>0.046082</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>-0.061401</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>-0.017426</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>-0.034882</td>\n",
       "      <td>-0.044739</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>-0.055084</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.059326</td>\n",
       "      <td>0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123965</th>\n",
       "      <td>Q9LY87</td>\n",
       "      <td>-0.011299</td>\n",
       "      <td>-0.036957</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.031891</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>-0.014832</td>\n",
       "      <td>-0.047791</td>\n",
       "      <td>0.055023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040680</td>\n",
       "      <td>-0.006996</td>\n",
       "      <td>0.018005</td>\n",
       "      <td>-0.024414</td>\n",
       "      <td>0.061401</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>-0.021011</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>0.019791</td>\n",
       "      <td>0.052887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123966</th>\n",
       "      <td>P22082</td>\n",
       "      <td>0.040405</td>\n",
       "      <td>-0.013908</td>\n",
       "      <td>0.025421</td>\n",
       "      <td>0.075012</td>\n",
       "      <td>-0.050293</td>\n",
       "      <td>0.058685</td>\n",
       "      <td>-0.032135</td>\n",
       "      <td>-0.073975</td>\n",
       "      <td>0.061798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066711</td>\n",
       "      <td>-0.011276</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>-0.014954</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>-0.010162</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>0.017517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123967</th>\n",
       "      <td>P63001</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>-0.026291</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>-0.044861</td>\n",
       "      <td>-0.003189</td>\n",
       "      <td>-0.009598</td>\n",
       "      <td>-0.061432</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037476</td>\n",
       "      <td>-0.020966</td>\n",
       "      <td>0.011360</td>\n",
       "      <td>0.027267</td>\n",
       "      <td>-0.006855</td>\n",
       "      <td>-0.005241</td>\n",
       "      <td>-0.057404</td>\n",
       "      <td>-0.012024</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.045898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123968</th>\n",
       "      <td>P28271</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>0.088684</td>\n",
       "      <td>-0.011307</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.059967</td>\n",
       "      <td>-0.099915</td>\n",
       "      <td>-0.042175</td>\n",
       "      <td>0.059662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063416</td>\n",
       "      <td>-0.009308</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>-0.014511</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>-0.042633</td>\n",
       "      <td>-0.009727</td>\n",
       "      <td>-0.068665</td>\n",
       "      <td>-0.048859</td>\n",
       "      <td>0.014969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84638 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protein_ID  Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  \\\n",
       "0          P91124  0.068176 -0.046478  0.001752 -0.008583  0.003763  0.046265   \n",
       "1          Q55DL5 -0.016434 -0.001583  0.003889  0.073425  0.012428  0.028168   \n",
       "2          O81027  0.007904  0.087708 -0.001715  0.037659  0.017883  0.025589   \n",
       "3          Q04418  0.002447  0.007053  0.064453  0.007271 -0.033569 -0.009933   \n",
       "5          Q7ZT12  0.056488  0.019241  0.112122  0.019608 -0.055939 -0.016129   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "123964     Q8LE52  0.052277 -0.062469  0.046478  0.046082 -0.041992 -0.009956   \n",
       "123965     Q9LY87 -0.011299 -0.036957  0.029297  0.031891  0.006027  0.079468   \n",
       "123966     P22082  0.040405 -0.013908  0.025421  0.075012 -0.050293  0.058685   \n",
       "123967     P63001 -0.008362 -0.026291  0.037354  0.033264 -0.044861 -0.003189   \n",
       "123968     P28271  0.014755  0.088684 -0.011307  0.012398  0.001452  0.059967   \n",
       "\n",
       "        Column_7  Column_8  Column_9  ...  Column_1015  Column_1016  \\\n",
       "0      -0.059662 -0.050385 -0.005173  ...    -0.040771    -0.013138   \n",
       "1      -0.040375 -0.093811 -0.017807  ...     0.011879    -0.033325   \n",
       "2      -0.011749 -0.084717 -0.016266  ...     0.004829    -0.049713   \n",
       "3      -0.022186 -0.083862 -0.003841  ...    -0.053589    -0.002508   \n",
       "5      -0.045105 -0.152466  0.003454  ...    -0.096985    -0.064880   \n",
       "...          ...       ...       ...  ...          ...          ...   \n",
       "123964  0.027161 -0.061401  0.038422  ...    -0.036865    -0.017426   \n",
       "123965 -0.014832 -0.047791  0.055023  ...    -0.040680    -0.006996   \n",
       "123966 -0.032135 -0.073975  0.061798  ...    -0.066711    -0.011276   \n",
       "123967 -0.009598 -0.061432  0.027451  ...    -0.037476    -0.020966   \n",
       "123968 -0.099915 -0.042175  0.059662  ...    -0.063416    -0.009308   \n",
       "\n",
       "        Column_1017  Column_1018  Column_1019  Column_1020  Column_1021  \\\n",
       "0         -0.049591    -0.101074     0.066406     0.008980    -0.003506   \n",
       "1         -0.031342    -0.005245     0.014732     0.081970     0.017456   \n",
       "2         -0.027176    -0.037415    -0.006241    -0.039703     0.001784   \n",
       "3         -0.016647    -0.069458     0.042206    -0.051758    -0.025436   \n",
       "5          0.009117    -0.106934     0.004780    -0.051544     0.001547   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "123964     0.019196    -0.034882    -0.044739     0.024338    -0.055084   \n",
       "123965     0.018005    -0.024414     0.061401     0.041229    -0.021011   \n",
       "123966     0.002800    -0.014954     0.015190     0.010483    -0.010162   \n",
       "123967     0.011360     0.027267    -0.006855    -0.005241    -0.057404   \n",
       "123968     0.101318    -0.014511     0.032562    -0.042633    -0.009727   \n",
       "\n",
       "        Column_1022  Column_1023  Column_1024  \n",
       "0         -0.024612     0.034760    -0.031006  \n",
       "1         -0.032959     0.053192     0.029907  \n",
       "2          0.004719    -0.004288     0.001847  \n",
       "3          0.057373     0.099121     0.032898  \n",
       "5         -0.038788     0.106018     0.013321  \n",
       "...             ...          ...          ...  \n",
       "123964     0.013901     0.059326     0.014725  \n",
       "123965    -0.014709     0.019791     0.052887  \n",
       "123966     0.027557     0.027039     0.017517  \n",
       "123967    -0.012024     0.000682     0.045898  \n",
       "123968    -0.068665    -0.048859     0.014969  \n",
       "\n",
       "[84638 rows x 1025 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123969, 687)\n"
     ]
    }
   ],
   "source": [
    "## TAKEN FROM OTHER NOTEBOOK\n",
    "## COMPILE Y LABLES INTO DF\n",
    "#num_of_labels = 1500 # CURRENTLY TAKING ALL\n",
    "num_of_labels = 687 # NUMBER OF CC GO TERMS\n",
    "\n",
    "# Take value counts in descending order and fetch first 1500 `GO term ID` as labels\n",
    "labels = train_set['GO_term'].value_counts().index[:num_of_labels].tolist()\n",
    "#labels = train_set['GO_term'].value_counts().tolist()\n",
    "# note added filtering for ONLY cellular component\n",
    "#train_set_updated = train_set.loc[train_set['GO_term'].isin(labels)]\n",
    "#train_set_updated = train_set.loc[train_set['GO_term'].isin(labels) & (train_set['aspect'] == 'cellular_component')]\n",
    "train_set_updated = train_set\n",
    "\n",
    "\n",
    "# Create an empty dataframe of required size for storing the labels,\n",
    "# i.e, train_size x num_of_labels (142246 x 1500)\n",
    "train_size = np.array(protein_ids).shape[0] # len(X)\n",
    "train_labels = np.zeros((train_size ,num_of_labels))\n",
    "\n",
    "# Convert from numpy to pandas series for better handling\n",
    "series_train_protein_ids = pd.Series(protein_ids)\n",
    "\n",
    "# Loop through each label\n",
    "for i in range(num_of_labels):\n",
    "    # For each label, fetch the corresponding train_terms data\n",
    "    n_train_terms = train_set_updated[train_set_updated['GO_term'] ==  labels[i]]\n",
    "    \n",
    "    # Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n",
    "    label_related_proteins = n_train_terms['Protein_ID'].unique()\n",
    "    \n",
    "    # In the series_train_protein_ids pandas series, if a protein is related\n",
    "    # to the current label, then mark it as 1, else 0.\n",
    "    # Replace the ith column of train_Y with with that pandas series.\n",
    "    train_labels[:,i] =  series_train_protein_ids.isin(label_related_proteins).astype(float)\n",
    "    \n",
    "\n",
    "# Convert train_Y numpy into pandas dataframe\n",
    "labels_df = pd.DataFrame(data = train_labels, columns = labels)\n",
    "print(labels_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GO:0005575</th>\n",
       "      <th>GO:0110165</th>\n",
       "      <th>GO:0008150</th>\n",
       "      <th>GO:0005622</th>\n",
       "      <th>GO:0043226</th>\n",
       "      <th>GO:0009987</th>\n",
       "      <th>GO:0003674</th>\n",
       "      <th>GO:0043229</th>\n",
       "      <th>GO:0043227</th>\n",
       "      <th>GO:0005737</th>\n",
       "      <th>...</th>\n",
       "      <th>GO:0099513</th>\n",
       "      <th>GO:0060090</th>\n",
       "      <th>GO:0006644</th>\n",
       "      <th>GO:0070848</th>\n",
       "      <th>GO:0019941</th>\n",
       "      <th>GO:0099177</th>\n",
       "      <th>GO:0050804</th>\n",
       "      <th>GO:1902532</th>\n",
       "      <th>GO:0005667</th>\n",
       "      <th>GO:0016798</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123964</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123965</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123966</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123967</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123968</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84638 rows × 687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GO:0005575  GO:0110165  GO:0008150  GO:0005622  GO:0043226  \\\n",
       "0              0.0         0.0         1.0         0.0         0.0   \n",
       "1              1.0         1.0         1.0         1.0         1.0   \n",
       "2              1.0         1.0         0.0         0.0         0.0   \n",
       "3              0.0         0.0         0.0         0.0         0.0   \n",
       "5              0.0         0.0         0.0         0.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "123964         1.0         1.0         0.0         1.0         1.0   \n",
       "123965         1.0         1.0         0.0         1.0         0.0   \n",
       "123966         1.0         1.0         0.0         1.0         1.0   \n",
       "123967         1.0         1.0         0.0         1.0         1.0   \n",
       "123968         1.0         1.0         0.0         1.0         1.0   \n",
       "\n",
       "        GO:0009987  GO:0003674  GO:0043229  GO:0043227  GO:0005737  ...  \\\n",
       "0              1.0         1.0         0.0         0.0         0.0  ...   \n",
       "1              1.0         0.0         1.0         1.0         0.0  ...   \n",
       "2              0.0         0.0         0.0         0.0         0.0  ...   \n",
       "3              0.0         1.0         0.0         0.0         0.0  ...   \n",
       "5              0.0         1.0         0.0         0.0         0.0  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "123964         0.0         0.0         1.0         1.0         1.0  ...   \n",
       "123965         0.0         0.0         0.0         0.0         1.0  ...   \n",
       "123966         0.0         0.0         1.0         1.0         0.0  ...   \n",
       "123967         0.0         0.0         1.0         1.0         1.0  ...   \n",
       "123968         0.0         0.0         1.0         1.0         1.0  ...   \n",
       "\n",
       "        GO:0099513  GO:0060090  GO:0006644  GO:0070848  GO:0019941  \\\n",
       "0              0.0         0.0         0.0         0.0         0.0   \n",
       "1              0.0         0.0         0.0         0.0         0.0   \n",
       "2              0.0         0.0         0.0         0.0         0.0   \n",
       "3              0.0         0.0         0.0         0.0         0.0   \n",
       "5              0.0         0.0         0.0         0.0         0.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "123964         0.0         0.0         0.0         0.0         0.0   \n",
       "123965         0.0         0.0         0.0         0.0         0.0   \n",
       "123966         0.0         0.0         0.0         0.0         0.0   \n",
       "123967         0.0         0.0         0.0         0.0         0.0   \n",
       "123968         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        GO:0099177  GO:0050804  GO:1902532  GO:0005667  GO:0016798  \n",
       "0              0.0         0.0         0.0         0.0         1.0  \n",
       "1              0.0         0.0         0.0         0.0         0.0  \n",
       "2              0.0         0.0         0.0         0.0         0.0  \n",
       "3              0.0         0.0         0.0         0.0         0.0  \n",
       "5              0.0         0.0         0.0         0.0         0.0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "123964         0.0         0.0         0.0         0.0         0.0  \n",
       "123965         0.0         0.0         0.0         0.0         0.0  \n",
       "123966         0.0         0.0         0.0         0.0         0.0  \n",
       "123967         0.0         0.0         0.0         0.0         0.0  \n",
       "123968         0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[84638 rows x 687 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cc_train\n",
    "y = labels_df.iloc[cc_train.index]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_1015</th>\n",
       "      <th>Column_1016</th>\n",
       "      <th>Column_1017</th>\n",
       "      <th>Column_1018</th>\n",
       "      <th>Column_1019</th>\n",
       "      <th>Column_1020</th>\n",
       "      <th>Column_1021</th>\n",
       "      <th>Column_1022</th>\n",
       "      <th>Column_1023</th>\n",
       "      <th>Column_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57275</th>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>-0.069641</td>\n",
       "      <td>-0.041473</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>-0.093079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063416</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>-0.056732</td>\n",
       "      <td>-0.028687</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>-0.038757</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>-0.034424</td>\n",
       "      <td>-0.005363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52450</th>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.030441</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>-0.015251</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>-0.049194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049438</td>\n",
       "      <td>-0.005131</td>\n",
       "      <td>-0.036255</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>-0.034637</td>\n",
       "      <td>-0.038910</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.013496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95625</th>\n",
       "      <td>0.051056</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-0.057098</td>\n",
       "      <td>-0.048828</td>\n",
       "      <td>-0.009148</td>\n",
       "      <td>-0.005997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019196</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>-0.081177</td>\n",
       "      <td>-0.008156</td>\n",
       "      <td>-0.020996</td>\n",
       "      <td>-0.029602</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.057587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82884</th>\n",
       "      <td>0.005070</td>\n",
       "      <td>-0.087769</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>-0.031586</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.080261</td>\n",
       "      <td>-0.009590</td>\n",
       "      <td>0.039459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>-0.013573</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>-0.088745</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.033356</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.028503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>0.048859</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.028473</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>-0.032684</td>\n",
       "      <td>-0.060638</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>-0.057465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086853</td>\n",
       "      <td>-0.044769</td>\n",
       "      <td>-0.004410</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.023636</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.029343</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>-0.007362</td>\n",
       "      <td>0.019119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.042175</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>-0.031525</td>\n",
       "      <td>-0.046387</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>0.012962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>-0.003323</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.046783</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>-0.026703</td>\n",
       "      <td>-0.013672</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79816</th>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.042206</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>-0.019135</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>-0.031647</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>-0.000672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023254</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.004513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112326</th>\n",
       "      <td>-0.059113</td>\n",
       "      <td>-0.035980</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>-0.006058</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>-0.040802</td>\n",
       "      <td>-0.094666</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>-0.015854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>-0.019028</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>-0.084106</td>\n",
       "      <td>-0.029053</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>-0.012566</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>0.071411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>-0.057343</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.013527</td>\n",
       "      <td>0.034576</td>\n",
       "      <td>0.040253</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>-0.088562</td>\n",
       "      <td>0.021774</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042542</td>\n",
       "      <td>-0.014931</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>-0.056580</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.037170</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22443</th>\n",
       "      <td>0.039154</td>\n",
       "      <td>-0.046906</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>-0.042847</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>-0.047089</td>\n",
       "      <td>-0.057037</td>\n",
       "      <td>-0.050629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062866</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>-0.057037</td>\n",
       "      <td>-0.022293</td>\n",
       "      <td>0.090576</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>0.027115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67710 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  Column_7  \\\n",
       "57275   0.067383  0.030548  0.011909  0.045471 -0.006641  0.045868 -0.069641   \n",
       "52450   0.031525  0.120117  0.030441  0.011177 -0.015251  0.007626 -0.009270   \n",
       "95625   0.051056  0.008263  0.076172  0.035522  0.027252  0.106445 -0.057098   \n",
       "82884   0.005070 -0.087769 -0.000177  0.012009 -0.031586  0.063477 -0.005371   \n",
       "6587    0.048859  0.030548  0.028473 -0.003517  0.001398  0.072449 -0.032684   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "8779    0.018784  0.037048  0.030228  0.042175  0.011719  0.020966 -0.031525   \n",
       "79816   0.018982  0.042206  0.025177  0.014626 -0.019135  0.024353 -0.030472   \n",
       "112326 -0.059113 -0.035980  0.055695 -0.006058 -0.028595  0.024200 -0.040802   \n",
       "1209   -0.057343 -0.015625 -0.013527  0.034576  0.040253  0.017014  0.001482   \n",
       "22443   0.039154 -0.046906  0.052490  0.046875  0.012787 -0.042847  0.035278   \n",
       "\n",
       "        Column_8  Column_9  Column_10  ...  Column_1015  Column_1016  \\\n",
       "57275  -0.041473 -0.015045  -0.093079  ...    -0.063416    -0.002037   \n",
       "52450  -0.074280  0.023544  -0.049194  ...    -0.049438    -0.005131   \n",
       "95625  -0.048828 -0.009148  -0.005997  ...    -0.019196     0.032745   \n",
       "82884  -0.080261 -0.009590   0.039459  ...     0.026810    -0.013573   \n",
       "6587   -0.060638  0.038696  -0.057465  ...    -0.086853    -0.044769   \n",
       "...          ...       ...        ...  ...          ...          ...   \n",
       "8779   -0.046387 -0.000349   0.012962  ...     0.014015     0.002598   \n",
       "79816  -0.031647  0.053802  -0.000672  ...    -0.023254     0.017014   \n",
       "112326 -0.094666 -0.003313  -0.015854  ...     0.046387    -0.019028   \n",
       "1209   -0.088562  0.021774   0.001718  ...    -0.042542    -0.014931   \n",
       "22443  -0.047089 -0.057037  -0.050629  ...    -0.062866    -0.015640   \n",
       "\n",
       "        Column_1017  Column_1018  Column_1019  Column_1020  Column_1021  \\\n",
       "57275     -0.056732    -0.028687     0.029861    -0.021347    -0.038757   \n",
       "52450     -0.036255    -0.018921     0.042023    -0.016327    -0.034637   \n",
       "95625      0.022354    -0.081177    -0.008156    -0.020996    -0.029602   \n",
       "82884      0.019730    -0.088745     0.008553     0.083008     0.035980   \n",
       "6587      -0.004410     0.012207     0.023636    -0.014793    -0.029343   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "8779      -0.003323     0.001747     0.046783     0.005169    -0.026703   \n",
       "79816      0.012650    -0.019287     0.023941    -0.009338     0.023270   \n",
       "112326     0.029236    -0.084106    -0.029053    -0.004059     0.003288   \n",
       "1209       0.013908    -0.056580     0.017578    -0.004860    -0.037170   \n",
       "22443     -0.057037    -0.022293     0.090576     0.015526     0.043945   \n",
       "\n",
       "        Column_1022  Column_1023  Column_1024  \n",
       "57275      0.034363    -0.034424    -0.005363  \n",
       "52450     -0.038910     0.007427     0.013496  \n",
       "95625      0.045105     0.023331     0.057587  \n",
       "82884      0.033356     0.042480     0.028503  \n",
       "6587      -0.018967    -0.007362     0.019119  \n",
       "...             ...          ...          ...  \n",
       "8779      -0.013672    -0.030441    -0.000006  \n",
       "79816      0.032288     0.015869    -0.004513  \n",
       "112326    -0.012566     0.042389     0.071411  \n",
       "1209       0.017471     0.076111     0.005451  \n",
       "22443      0.007786     0.070190     0.027115  \n",
       "\n",
       "[67710 rows x 1024 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 6s 299ms/step - loss: 0.4113 - binary_accuracy: 0.8405 - average_precision: 0.0415 - val_loss: 0.4683 - val_binary_accuracy: 0.9596 - val_average_precision: 0.0503\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 3s 245ms/step - loss: 0.1662 - binary_accuracy: 0.9590 - average_precision: 0.0535 - val_loss: 0.5797 - val_binary_accuracy: 0.9604 - val_average_precision: 0.0546\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 3s 251ms/step - loss: 0.1398 - binary_accuracy: 0.9609 - average_precision: 0.0539 - val_loss: 0.5505 - val_binary_accuracy: 0.9607 - val_average_precision: 0.0609\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 3s 248ms/step - loss: 0.1341 - binary_accuracy: 0.9612 - average_precision: 0.0693 - val_loss: 0.5364 - val_binary_accuracy: 0.9611 - val_average_precision: 0.0647\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 3s 250ms/step - loss: 0.1306 - binary_accuracy: 0.9615 - average_precision: 0.0803 - val_loss: 0.5326 - val_binary_accuracy: 0.9614 - val_average_precision: 0.0821\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 3s 247ms/step - loss: 0.1270 - binary_accuracy: 0.9618 - average_precision: 0.0941 - val_loss: 0.5231 - val_binary_accuracy: 0.9617 - val_average_precision: 0.0955\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 3s 253ms/step - loss: 0.1236 - binary_accuracy: 0.9621 - average_precision: 0.1097 - val_loss: 0.5084 - val_binary_accuracy: 0.9619 - val_average_precision: 0.1120\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.1205 - binary_accuracy: 0.9624 - average_precision: 0.1255 - val_loss: 0.4942 - val_binary_accuracy: 0.9621 - val_average_precision: 0.1262\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 3s 249ms/step - loss: 0.1179 - binary_accuracy: 0.9626 - average_precision: 0.1403 - val_loss: 0.4774 - val_binary_accuracy: 0.9622 - val_average_precision: 0.1380\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.1157 - binary_accuracy: 0.9628 - average_precision: 0.1528 - val_loss: 0.4617 - val_binary_accuracy: 0.9625 - val_average_precision: 0.1485\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.1141 - binary_accuracy: 0.9630 - average_precision: 0.1630 - val_loss: 0.4473 - val_binary_accuracy: 0.9626 - val_average_precision: 0.1567\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 3s 251ms/step - loss: 0.1126 - binary_accuracy: 0.9632 - average_precision: 0.1726 - val_loss: 0.4307 - val_binary_accuracy: 0.9627 - val_average_precision: 0.1658\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.1114 - binary_accuracy: 0.9634 - average_precision: 0.1821 - val_loss: 0.4186 - val_binary_accuracy: 0.9628 - val_average_precision: 0.1733\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.1103 - binary_accuracy: 0.9635 - average_precision: 0.1901 - val_loss: 0.4050 - val_binary_accuracy: 0.9629 - val_average_precision: 0.1803\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.1093 - binary_accuracy: 0.9637 - average_precision: 0.1979 - val_loss: 0.3923 - val_binary_accuracy: 0.9630 - val_average_precision: 0.1863\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 3s 251ms/step - loss: 0.1083 - binary_accuracy: 0.9638 - average_precision: 0.2049 - val_loss: 0.3799 - val_binary_accuracy: 0.9632 - val_average_precision: 0.1904\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 0.1075 - binary_accuracy: 0.9640 - average_precision: 0.2115 - val_loss: 0.3654 - val_binary_accuracy: 0.9633 - val_average_precision: 0.1957\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.1067 - binary_accuracy: 0.9641 - average_precision: 0.2173 - val_loss: 0.3549 - val_binary_accuracy: 0.9633 - val_average_precision: 0.1995\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.1059 - binary_accuracy: 0.9643 - average_precision: 0.2241 - val_loss: 0.3400 - val_binary_accuracy: 0.9635 - val_average_precision: 0.2035\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 4s 264ms/step - loss: 0.1051 - binary_accuracy: 0.9644 - average_precision: 0.2300 - val_loss: 0.3294 - val_binary_accuracy: 0.9635 - val_average_precision: 0.2073\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.1043 - binary_accuracy: 0.9646 - average_precision: 0.2360 - val_loss: 0.3199 - val_binary_accuracy: 0.9633 - val_average_precision: 0.2087\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 4s 287ms/step - loss: 0.1037 - binary_accuracy: 0.9647 - average_precision: 0.2416 - val_loss: 0.3052 - val_binary_accuracy: 0.9633 - val_average_precision: 0.2121\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.1030 - binary_accuracy: 0.9649 - average_precision: 0.2474 - val_loss: 0.2936 - val_binary_accuracy: 0.9634 - val_average_precision: 0.2148\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 4s 287ms/step - loss: 0.1024 - binary_accuracy: 0.9650 - average_precision: 0.2527 - val_loss: 0.2851 - val_binary_accuracy: 0.9627 - val_average_precision: 0.2174\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.1016 - binary_accuracy: 0.9652 - average_precision: 0.2586 - val_loss: 0.2630 - val_binary_accuracy: 0.9636 - val_average_precision: 0.2186\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 5s 368ms/step - loss: 0.1010 - binary_accuracy: 0.9653 - average_precision: 0.2639 - val_loss: 0.2578 - val_binary_accuracy: 0.9629 - val_average_precision: 0.2219\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 6s 439ms/step - loss: 0.1002 - binary_accuracy: 0.9655 - average_precision: 0.2704 - val_loss: 0.2394 - val_binary_accuracy: 0.9633 - val_average_precision: 0.2225\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 4s 307ms/step - loss: 0.0998 - binary_accuracy: 0.9656 - average_precision: 0.2741 - val_loss: 0.2315 - val_binary_accuracy: 0.9630 - val_average_precision: 0.2240\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0990 - binary_accuracy: 0.9658 - average_precision: 0.2796 - val_loss: 0.2208 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2257\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 4s 280ms/step - loss: 0.0985 - binary_accuracy: 0.9660 - average_precision: 0.2847 - val_loss: 0.2092 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2270\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.0979 - binary_accuracy: 0.9661 - average_precision: 0.2896 - val_loss: 0.2009 - val_binary_accuracy: 0.9619 - val_average_precision: 0.2280\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0973 - binary_accuracy: 0.9663 - average_precision: 0.2944 - val_loss: 0.1903 - val_binary_accuracy: 0.9622 - val_average_precision: 0.2284\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0967 - binary_accuracy: 0.9664 - average_precision: 0.2984 - val_loss: 0.1753 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2302\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0962 - binary_accuracy: 0.9665 - average_precision: 0.3028 - val_loss: 0.1700 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2321\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 4s 260ms/step - loss: 0.0955 - binary_accuracy: 0.9667 - average_precision: 0.3084 - val_loss: 0.1599 - val_binary_accuracy: 0.9627 - val_average_precision: 0.2319\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0951 - binary_accuracy: 0.9668 - average_precision: 0.3113 - val_loss: 0.1544 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2321\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 4s 259ms/step - loss: 0.0947 - binary_accuracy: 0.9670 - average_precision: 0.3153 - val_loss: 0.1475 - val_binary_accuracy: 0.9623 - val_average_precision: 0.2323\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0940 - binary_accuracy: 0.9671 - average_precision: 0.3206 - val_loss: 0.1387 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2348\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0935 - binary_accuracy: 0.9673 - average_precision: 0.3247 - val_loss: 0.1346 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2361\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 4s 264ms/step - loss: 0.0928 - binary_accuracy: 0.9675 - average_precision: 0.3307 - val_loss: 0.1275 - val_binary_accuracy: 0.9630 - val_average_precision: 0.2362\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0924 - binary_accuracy: 0.9676 - average_precision: 0.3341 - val_loss: 0.1256 - val_binary_accuracy: 0.9626 - val_average_precision: 0.2360\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0921 - binary_accuracy: 0.9676 - average_precision: 0.3347 - val_loss: 0.1233 - val_binary_accuracy: 0.9622 - val_average_precision: 0.2381\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0918 - binary_accuracy: 0.9677 - average_precision: 0.3376 - val_loss: 0.1193 - val_binary_accuracy: 0.9625 - val_average_precision: 0.2388\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 4s 265ms/step - loss: 0.0916 - binary_accuracy: 0.9678 - average_precision: 0.3401 - val_loss: 0.1138 - val_binary_accuracy: 0.9635 - val_average_precision: 0.2401\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0908 - binary_accuracy: 0.9680 - average_precision: 0.3461 - val_loss: 0.1178 - val_binary_accuracy: 0.9622 - val_average_precision: 0.2407\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 4s 317ms/step - loss: 0.0901 - binary_accuracy: 0.9683 - average_precision: 0.3522 - val_loss: 0.1124 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2409\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 4s 298ms/step - loss: 0.0896 - binary_accuracy: 0.9684 - average_precision: 0.3557 - val_loss: 0.1118 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2422\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0891 - binary_accuracy: 0.9685 - average_precision: 0.3602 - val_loss: 0.1119 - val_binary_accuracy: 0.9626 - val_average_precision: 0.2412\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0889 - binary_accuracy: 0.9686 - average_precision: 0.3621 - val_loss: 0.1117 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2392\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0886 - binary_accuracy: 0.9687 - average_precision: 0.3637 - val_loss: 0.1104 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2393\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 6s 428ms/step - loss: 0.0882 - binary_accuracy: 0.9688 - average_precision: 0.3669 - val_loss: 0.1100 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2424\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 4s 300ms/step - loss: 0.0877 - binary_accuracy: 0.9689 - average_precision: 0.3716 - val_loss: 0.1105 - val_binary_accuracy: 0.9627 - val_average_precision: 0.2409\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 4s 289ms/step - loss: 0.0873 - binary_accuracy: 0.9690 - average_precision: 0.3745 - val_loss: 0.1105 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2425\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 4s 310ms/step - loss: 0.0867 - binary_accuracy: 0.9692 - average_precision: 0.3790 - val_loss: 0.1106 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2404\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 4s 304ms/step - loss: 0.0864 - binary_accuracy: 0.9693 - average_precision: 0.3814 - val_loss: 0.1110 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2436\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.0860 - binary_accuracy: 0.9695 - average_precision: 0.3849 - val_loss: 0.1109 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2405\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0861 - binary_accuracy: 0.9694 - average_precision: 0.3837 - val_loss: 0.1107 - val_binary_accuracy: 0.9630 - val_average_precision: 0.2439\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0855 - binary_accuracy: 0.9696 - average_precision: 0.3890 - val_loss: 0.1112 - val_binary_accuracy: 0.9626 - val_average_precision: 0.2429\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 4s 284ms/step - loss: 0.0850 - binary_accuracy: 0.9698 - average_precision: 0.3932 - val_loss: 0.1110 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2440\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0848 - binary_accuracy: 0.9698 - average_precision: 0.3954 - val_loss: 0.1115 - val_binary_accuracy: 0.9634 - val_average_precision: 0.2425\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0843 - binary_accuracy: 0.9700 - average_precision: 0.3989 - val_loss: 0.1116 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2441\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0840 - binary_accuracy: 0.9700 - average_precision: 0.4003 - val_loss: 0.1134 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2446\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 4s 289ms/step - loss: 0.0840 - binary_accuracy: 0.9701 - average_precision: 0.4010 - val_loss: 0.1122 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2446\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 4s 300ms/step - loss: 0.0835 - binary_accuracy: 0.9702 - average_precision: 0.4050 - val_loss: 0.1129 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2431\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0833 - binary_accuracy: 0.9702 - average_precision: 0.4061 - val_loss: 0.1132 - val_binary_accuracy: 0.9626 - val_average_precision: 0.2406\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0834 - binary_accuracy: 0.9702 - average_precision: 0.4052 - val_loss: 0.1133 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2439\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0832 - binary_accuracy: 0.9702 - average_precision: 0.4074 - val_loss: 0.1137 - val_binary_accuracy: 0.9632 - val_average_precision: 0.2431\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0824 - binary_accuracy: 0.9705 - average_precision: 0.4136 - val_loss: 0.1134 - val_binary_accuracy: 0.9630 - val_average_precision: 0.2451\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0818 - binary_accuracy: 0.9708 - average_precision: 0.4197 - val_loss: 0.1139 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2447\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0816 - binary_accuracy: 0.9708 - average_precision: 0.4207 - val_loss: 0.1145 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2436\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0817 - binary_accuracy: 0.9707 - average_precision: 0.4202 - val_loss: 0.1147 - val_binary_accuracy: 0.9623 - val_average_precision: 0.2449\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0809 - binary_accuracy: 0.9710 - average_precision: 0.4265 - val_loss: 0.1158 - val_binary_accuracy: 0.9619 - val_average_precision: 0.2440\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0807 - binary_accuracy: 0.9711 - average_precision: 0.4274 - val_loss: 0.1154 - val_binary_accuracy: 0.9623 - val_average_precision: 0.2429\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0803 - binary_accuracy: 0.9712 - average_precision: 0.4313 - val_loss: 0.1157 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2426\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0801 - binary_accuracy: 0.9713 - average_precision: 0.4332 - val_loss: 0.1169 - val_binary_accuracy: 0.9630 - val_average_precision: 0.2442\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 4s 265ms/step - loss: 0.0799 - binary_accuracy: 0.9713 - average_precision: 0.4349 - val_loss: 0.1173 - val_binary_accuracy: 0.9632 - val_average_precision: 0.2417\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0798 - binary_accuracy: 0.9713 - average_precision: 0.4347 - val_loss: 0.1167 - val_binary_accuracy: 0.9625 - val_average_precision: 0.2408\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0794 - binary_accuracy: 0.9715 - average_precision: 0.4379 - val_loss: 0.1170 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2435\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 4s 268ms/step - loss: 0.0790 - binary_accuracy: 0.9716 - average_precision: 0.4417 - val_loss: 0.1171 - val_binary_accuracy: 0.9625 - val_average_precision: 0.2431\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 4s 265ms/step - loss: 0.0787 - binary_accuracy: 0.9717 - average_precision: 0.4449 - val_loss: 0.1174 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2422\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 4s 265ms/step - loss: 0.0791 - binary_accuracy: 0.9715 - average_precision: 0.4406 - val_loss: 0.1184 - val_binary_accuracy: 0.9629 - val_average_precision: 0.2416\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 4s 273ms/step - loss: 0.0788 - binary_accuracy: 0.9716 - average_precision: 0.4435 - val_loss: 0.1195 - val_binary_accuracy: 0.9631 - val_average_precision: 0.2418\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0786 - binary_accuracy: 0.9717 - average_precision: 0.4450 - val_loss: 0.1186 - val_binary_accuracy: 0.9628 - val_average_precision: 0.2427\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0780 - binary_accuracy: 0.9719 - average_precision: 0.4501 - val_loss: 0.1187 - val_binary_accuracy: 0.9625 - val_average_precision: 0.2424\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0777 - binary_accuracy: 0.9720 - average_precision: 0.4530 - val_loss: 0.1188 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2430\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 4s 318ms/step - loss: 0.0776 - binary_accuracy: 0.9720 - average_precision: 0.4534 - val_loss: 0.1193 - val_binary_accuracy: 0.9622 - val_average_precision: 0.2419\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 4s 263ms/step - loss: 0.0772 - binary_accuracy: 0.9721 - average_precision: 0.4565 - val_loss: 0.1192 - val_binary_accuracy: 0.9623 - val_average_precision: 0.2446\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0770 - binary_accuracy: 0.9722 - average_precision: 0.4590 - val_loss: 0.1202 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2435\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 4s 263ms/step - loss: 0.0770 - binary_accuracy: 0.9722 - average_precision: 0.4586 - val_loss: 0.1204 - val_binary_accuracy: 0.9619 - val_average_precision: 0.2437\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0768 - binary_accuracy: 0.9723 - average_precision: 0.4599 - val_loss: 0.1202 - val_binary_accuracy: 0.9621 - val_average_precision: 0.2429\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 4s 262ms/step - loss: 0.0763 - binary_accuracy: 0.9724 - average_precision: 0.4642 - val_loss: 0.1209 - val_binary_accuracy: 0.9610 - val_average_precision: 0.2449\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0768 - binary_accuracy: 0.9723 - average_precision: 0.4607 - val_loss: 0.1221 - val_binary_accuracy: 0.9601 - val_average_precision: 0.2439\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0769 - binary_accuracy: 0.9722 - average_precision: 0.4597 - val_loss: 0.1209 - val_binary_accuracy: 0.9609 - val_average_precision: 0.2423\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0762 - binary_accuracy: 0.9725 - average_precision: 0.4651 - val_loss: 0.1208 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2423\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0759 - binary_accuracy: 0.9726 - average_precision: 0.4685 - val_loss: 0.1209 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2443\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 4s 259ms/step - loss: 0.0752 - binary_accuracy: 0.9728 - average_precision: 0.4739 - val_loss: 0.1217 - val_binary_accuracy: 0.9613 - val_average_precision: 0.2439\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0753 - binary_accuracy: 0.9728 - average_precision: 0.4732 - val_loss: 0.1218 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2426\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0748 - binary_accuracy: 0.9729 - average_precision: 0.4768 - val_loss: 0.1223 - val_binary_accuracy: 0.9613 - val_average_precision: 0.2419\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 4s 259ms/step - loss: 0.0749 - binary_accuracy: 0.9729 - average_precision: 0.4766 - val_loss: 0.1225 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2426\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0746 - binary_accuracy: 0.9730 - average_precision: 0.4779 - val_loss: 0.1233 - val_binary_accuracy: 0.9606 - val_average_precision: 0.2431\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 4s 263ms/step - loss: 0.0745 - binary_accuracy: 0.9730 - average_precision: 0.4789 - val_loss: 0.1228 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2433\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0740 - binary_accuracy: 0.9732 - average_precision: 0.4834 - val_loss: 0.1239 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2452\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 4s 252ms/step - loss: 0.0746 - binary_accuracy: 0.9730 - average_precision: 0.4787 - val_loss: 0.1231 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2430\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0738 - binary_accuracy: 0.9733 - average_precision: 0.4857 - val_loss: 0.1233 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2436\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 4s 269ms/step - loss: 0.0734 - binary_accuracy: 0.9734 - average_precision: 0.4884 - val_loss: 0.1241 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2425\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0733 - binary_accuracy: 0.9734 - average_precision: 0.4889 - val_loss: 0.1246 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2415\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0733 - binary_accuracy: 0.9734 - average_precision: 0.4891 - val_loss: 0.1250 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2421\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0734 - binary_accuracy: 0.9733 - average_precision: 0.4887 - val_loss: 0.1248 - val_binary_accuracy: 0.9611 - val_average_precision: 0.2446\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0732 - binary_accuracy: 0.9735 - average_precision: 0.4908 - val_loss: 0.1253 - val_binary_accuracy: 0.9619 - val_average_precision: 0.2397\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 0.0728 - binary_accuracy: 0.9736 - average_precision: 0.4937 - val_loss: 0.1254 - val_binary_accuracy: 0.9618 - val_average_precision: 0.2434\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 4s 262ms/step - loss: 0.0728 - binary_accuracy: 0.9736 - average_precision: 0.4934 - val_loss: 0.1263 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2403\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 4s 266ms/step - loss: 0.0730 - binary_accuracy: 0.9735 - average_precision: 0.4923 - val_loss: 0.1266 - val_binary_accuracy: 0.9624 - val_average_precision: 0.2395\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 0.0731 - binary_accuracy: 0.9734 - average_precision: 0.4911 - val_loss: 0.1266 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2382\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0727 - binary_accuracy: 0.9736 - average_precision: 0.4948 - val_loss: 0.1265 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2402\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0726 - binary_accuracy: 0.9736 - average_precision: 0.4965 - val_loss: 0.1270 - val_binary_accuracy: 0.9620 - val_average_precision: 0.2389\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0723 - binary_accuracy: 0.9737 - average_precision: 0.4977 - val_loss: 0.1264 - val_binary_accuracy: 0.9611 - val_average_precision: 0.2432\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 4s 253ms/step - loss: 0.0717 - binary_accuracy: 0.9740 - average_precision: 0.5033 - val_loss: 0.1263 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2422\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0713 - binary_accuracy: 0.9741 - average_precision: 0.5066 - val_loss: 0.1269 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2427\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0710 - binary_accuracy: 0.9742 - average_precision: 0.5092 - val_loss: 0.1275 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2406\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0710 - binary_accuracy: 0.9742 - average_precision: 0.5099 - val_loss: 0.1281 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2406\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0710 - binary_accuracy: 0.9742 - average_precision: 0.5090 - val_loss: 0.1284 - val_binary_accuracy: 0.9603 - val_average_precision: 0.2401\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0711 - binary_accuracy: 0.9741 - average_precision: 0.5077 - val_loss: 0.1297 - val_binary_accuracy: 0.9590 - val_average_precision: 0.2432\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0716 - binary_accuracy: 0.9739 - average_precision: 0.5045 - val_loss: 0.1293 - val_binary_accuracy: 0.9595 - val_average_precision: 0.2445\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0711 - binary_accuracy: 0.9741 - average_precision: 0.5091 - val_loss: 0.1285 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2419\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0706 - binary_accuracy: 0.9743 - average_precision: 0.5139 - val_loss: 0.1291 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2446\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0705 - binary_accuracy: 0.9743 - average_precision: 0.5140 - val_loss: 0.1292 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2406\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0702 - binary_accuracy: 0.9745 - average_precision: 0.5163 - val_loss: 0.1297 - val_binary_accuracy: 0.9607 - val_average_precision: 0.2387\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0699 - binary_accuracy: 0.9746 - average_precision: 0.5191 - val_loss: 0.1295 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2424\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0697 - binary_accuracy: 0.9746 - average_precision: 0.5206 - val_loss: 0.1302 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2409\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0695 - binary_accuracy: 0.9747 - average_precision: 0.5223 - val_loss: 0.1308 - val_binary_accuracy: 0.9618 - val_average_precision: 0.2399\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0696 - binary_accuracy: 0.9746 - average_precision: 0.5212 - val_loss: 0.1313 - val_binary_accuracy: 0.9619 - val_average_precision: 0.2396\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0701 - binary_accuracy: 0.9744 - average_precision: 0.5169 - val_loss: 0.1312 - val_binary_accuracy: 0.9618 - val_average_precision: 0.2375\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0694 - binary_accuracy: 0.9747 - average_precision: 0.5231 - val_loss: 0.1308 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2423\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0689 - binary_accuracy: 0.9749 - average_precision: 0.5269 - val_loss: 0.1311 - val_binary_accuracy: 0.9615 - val_average_precision: 0.2401\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0690 - binary_accuracy: 0.9749 - average_precision: 0.5264 - val_loss: 0.1318 - val_binary_accuracy: 0.9613 - val_average_precision: 0.2373\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0692 - binary_accuracy: 0.9748 - average_precision: 0.5247 - val_loss: 0.1321 - val_binary_accuracy: 0.9616 - val_average_precision: 0.2380\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0691 - binary_accuracy: 0.9748 - average_precision: 0.5253 - val_loss: 0.1319 - val_binary_accuracy: 0.9600 - val_average_precision: 0.2413\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 4s 254ms/step - loss: 0.0686 - binary_accuracy: 0.9750 - average_precision: 0.5295 - val_loss: 0.1322 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2401\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 4s 261ms/step - loss: 0.0682 - binary_accuracy: 0.9751 - average_precision: 0.5333 - val_loss: 0.1331 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2399\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0683 - binary_accuracy: 0.9751 - average_precision: 0.5325 - val_loss: 0.1326 - val_binary_accuracy: 0.9609 - val_average_precision: 0.2403\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0683 - binary_accuracy: 0.9751 - average_precision: 0.5324 - val_loss: 0.1331 - val_binary_accuracy: 0.9614 - val_average_precision: 0.2396\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 4s 258ms/step - loss: 0.0680 - binary_accuracy: 0.9752 - average_precision: 0.5352 - val_loss: 0.1330 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2408\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 4s 257ms/step - loss: 0.0678 - binary_accuracy: 0.9753 - average_precision: 0.5370 - val_loss: 0.1336 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2414\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0678 - binary_accuracy: 0.9752 - average_precision: 0.5366 - val_loss: 0.1349 - val_binary_accuracy: 0.9610 - val_average_precision: 0.2373\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 4s 255ms/step - loss: 0.0677 - binary_accuracy: 0.9753 - average_precision: 0.5373 - val_loss: 0.1345 - val_binary_accuracy: 0.9610 - val_average_precision: 0.2403\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 4s 267ms/step - loss: 0.0677 - binary_accuracy: 0.9753 - average_precision: 0.5376 - val_loss: 0.1347 - val_binary_accuracy: 0.9612 - val_average_precision: 0.2373\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0674 - binary_accuracy: 0.9754 - average_precision: 0.5404 - val_loss: 0.1347 - val_binary_accuracy: 0.9596 - val_average_precision: 0.2397\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 4s 256ms/step - loss: 0.0674 - binary_accuracy: 0.9754 - average_precision: 0.5408 - val_loss: 0.1354 - val_binary_accuracy: 0.9601 - val_average_precision: 0.2411\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 4s 298ms/step - loss: 0.0676 - binary_accuracy: 0.9753 - average_precision: 0.5382 - val_loss: 0.1354 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2390\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 4s 276ms/step - loss: 0.0674 - binary_accuracy: 0.9754 - average_precision: 0.5408 - val_loss: 0.1362 - val_binary_accuracy: 0.9617 - val_average_precision: 0.2374\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0672 - binary_accuracy: 0.9754 - average_precision: 0.5427 - val_loss: 0.1356 - val_binary_accuracy: 0.9610 - val_average_precision: 0.2382\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0672 - binary_accuracy: 0.9755 - average_precision: 0.5425 - val_loss: 0.1358 - val_binary_accuracy: 0.9607 - val_average_precision: 0.2397\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0668 - binary_accuracy: 0.9756 - average_precision: 0.5463 - val_loss: 0.1358 - val_binary_accuracy: 0.9597 - val_average_precision: 0.2400\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0666 - binary_accuracy: 0.9757 - average_precision: 0.5474 - val_loss: 0.1363 - val_binary_accuracy: 0.9603 - val_average_precision: 0.2387\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 4s 270ms/step - loss: 0.0663 - binary_accuracy: 0.9757 - average_precision: 0.5494 - val_loss: 0.1367 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2389\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0662 - binary_accuracy: 0.9758 - average_precision: 0.5508 - val_loss: 0.1382 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2362\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 4s 303ms/step - loss: 0.0665 - binary_accuracy: 0.9756 - average_precision: 0.5477 - val_loss: 0.1369 - val_binary_accuracy: 0.9598 - val_average_precision: 0.2408\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0662 - binary_accuracy: 0.9758 - average_precision: 0.5503 - val_loss: 0.1370 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2376\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 4s 274ms/step - loss: 0.0660 - binary_accuracy: 0.9759 - average_precision: 0.5522 - val_loss: 0.1387 - val_binary_accuracy: 0.9613 - val_average_precision: 0.2371\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 4s 271ms/step - loss: 0.0663 - binary_accuracy: 0.9757 - average_precision: 0.5507 - val_loss: 0.1383 - val_binary_accuracy: 0.9601 - val_average_precision: 0.2377\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 4s 285ms/step - loss: 0.0661 - binary_accuracy: 0.9758 - average_precision: 0.5515 - val_loss: 0.1389 - val_binary_accuracy: 0.9589 - val_average_precision: 0.2388\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 4s 274ms/step - loss: 0.0663 - binary_accuracy: 0.9757 - average_precision: 0.5502 - val_loss: 0.1376 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2377\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0658 - binary_accuracy: 0.9759 - average_precision: 0.5547 - val_loss: 0.1390 - val_binary_accuracy: 0.9611 - val_average_precision: 0.2380\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.0656 - binary_accuracy: 0.9760 - average_precision: 0.5558 - val_loss: 0.1390 - val_binary_accuracy: 0.9611 - val_average_precision: 0.2396\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 4s 281ms/step - loss: 0.0653 - binary_accuracy: 0.9761 - average_precision: 0.5588 - val_loss: 0.1393 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2390\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 4s 274ms/step - loss: 0.0651 - binary_accuracy: 0.9762 - average_precision: 0.5596 - val_loss: 0.1389 - val_binary_accuracy: 0.9598 - val_average_precision: 0.2387\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0650 - binary_accuracy: 0.9762 - average_precision: 0.5613 - val_loss: 0.1396 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2374\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 4s 278ms/step - loss: 0.0650 - binary_accuracy: 0.9762 - average_precision: 0.5615 - val_loss: 0.1397 - val_binary_accuracy: 0.9597 - val_average_precision: 0.2370\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0648 - binary_accuracy: 0.9763 - average_precision: 0.5634 - val_loss: 0.1403 - val_binary_accuracy: 0.9599 - val_average_precision: 0.2366\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 4s 272ms/step - loss: 0.0649 - binary_accuracy: 0.9762 - average_precision: 0.5617 - val_loss: 0.1407 - val_binary_accuracy: 0.9596 - val_average_precision: 0.2366\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 4s 288ms/step - loss: 0.0648 - binary_accuracy: 0.9763 - average_precision: 0.5629 - val_loss: 0.1404 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2361\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 4s 303ms/step - loss: 0.0645 - binary_accuracy: 0.9764 - average_precision: 0.5655 - val_loss: 0.1409 - val_binary_accuracy: 0.9609 - val_average_precision: 0.2366\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 4s 291ms/step - loss: 0.0644 - binary_accuracy: 0.9764 - average_precision: 0.5660 - val_loss: 0.1418 - val_binary_accuracy: 0.9605 - val_average_precision: 0.2374\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0643 - binary_accuracy: 0.9764 - average_precision: 0.5674 - val_loss: 0.1428 - val_binary_accuracy: 0.9613 - val_average_precision: 0.2358\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 4s 283ms/step - loss: 0.0649 - binary_accuracy: 0.9762 - average_precision: 0.5624 - val_loss: 0.1418 - val_binary_accuracy: 0.9605 - val_average_precision: 0.2332\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 4s 294ms/step - loss: 0.0643 - binary_accuracy: 0.9765 - average_precision: 0.5683 - val_loss: 0.1421 - val_binary_accuracy: 0.9599 - val_average_precision: 0.2364\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 4s 279ms/step - loss: 0.0644 - binary_accuracy: 0.9764 - average_precision: 0.5663 - val_loss: 0.1438 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2323\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 4s 305ms/step - loss: 0.0647 - binary_accuracy: 0.9762 - average_precision: 0.5649 - val_loss: 0.1425 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2352\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 5s 366ms/step - loss: 0.0641 - binary_accuracy: 0.9765 - average_precision: 0.5690 - val_loss: 0.1428 - val_binary_accuracy: 0.9608 - val_average_precision: 0.2351\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 5s 346ms/step - loss: 0.0645 - binary_accuracy: 0.9763 - average_precision: 0.5658 - val_loss: 0.1432 - val_binary_accuracy: 0.9595 - val_average_precision: 0.2391\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 5s 323ms/step - loss: 0.0642 - binary_accuracy: 0.9764 - average_precision: 0.5685 - val_loss: 0.1423 - val_binary_accuracy: 0.9597 - val_average_precision: 0.2377\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 5s 352ms/step - loss: 0.0637 - binary_accuracy: 0.9767 - average_precision: 0.5731 - val_loss: 0.1433 - val_binary_accuracy: 0.9591 - val_average_precision: 0.2373\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 4s 286ms/step - loss: 0.0636 - binary_accuracy: 0.9767 - average_precision: 0.5738 - val_loss: 0.1429 - val_binary_accuracy: 0.9597 - val_average_precision: 0.2362\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0633 - binary_accuracy: 0.9768 - average_precision: 0.5762 - val_loss: 0.1434 - val_binary_accuracy: 0.9603 - val_average_precision: 0.2359\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 4s 277ms/step - loss: 0.0631 - binary_accuracy: 0.9769 - average_precision: 0.5788 - val_loss: 0.1443 - val_binary_accuracy: 0.9583 - val_average_precision: 0.2376\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 4s 301ms/step - loss: 0.0634 - binary_accuracy: 0.9767 - average_precision: 0.5753 - val_loss: 0.1436 - val_binary_accuracy: 0.9606 - val_average_precision: 0.2349\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 4s 311ms/step - loss: 0.0632 - binary_accuracy: 0.9768 - average_precision: 0.5777 - val_loss: 0.1453 - val_binary_accuracy: 0.9607 - val_average_precision: 0.2330\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 4s 322ms/step - loss: 0.0634 - binary_accuracy: 0.9767 - average_precision: 0.5756 - val_loss: 0.1444 - val_binary_accuracy: 0.9599 - val_average_precision: 0.2368\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 4s 305ms/step - loss: 0.0630 - binary_accuracy: 0.9768 - average_precision: 0.5789 - val_loss: 0.1450 - val_binary_accuracy: 0.9602 - val_average_precision: 0.2334\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 4s 296ms/step - loss: 0.0627 - binary_accuracy: 0.9770 - average_precision: 0.5816 - val_loss: 0.1451 - val_binary_accuracy: 0.9598 - val_average_precision: 0.2369\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 4s 308ms/step - loss: 0.0626 - binary_accuracy: 0.9770 - average_precision: 0.5823 - val_loss: 0.1459 - val_binary_accuracy: 0.9603 - val_average_precision: 0.2334\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.0627 - binary_accuracy: 0.9770 - average_precision: 0.5813 - val_loss: 0.1455 - val_binary_accuracy: 0.9587 - val_average_precision: 0.2353\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 4s 312ms/step - loss: 0.0629 - binary_accuracy: 0.9768 - average_precision: 0.5799 - val_loss: 0.1458 - val_binary_accuracy: 0.9591 - val_average_precision: 0.2353\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 4s 303ms/step - loss: 0.0626 - binary_accuracy: 0.9770 - average_precision: 0.5831 - val_loss: 0.1463 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2369\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 4s 299ms/step - loss: 0.0626 - binary_accuracy: 0.9770 - average_precision: 0.5822 - val_loss: 0.1465 - val_binary_accuracy: 0.9601 - val_average_precision: 0.2336\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0626 - binary_accuracy: 0.9770 - average_precision: 0.5832 - val_loss: 0.1469 - val_binary_accuracy: 0.9601 - val_average_precision: 0.2339\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 4s 292ms/step - loss: 0.0622 - binary_accuracy: 0.9772 - average_precision: 0.5867 - val_loss: 0.1469 - val_binary_accuracy: 0.9591 - val_average_precision: 0.2335\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 4s 299ms/step - loss: 0.0622 - binary_accuracy: 0.9772 - average_precision: 0.5857 - val_loss: 0.1466 - val_binary_accuracy: 0.9597 - val_average_precision: 0.2347\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0623 - binary_accuracy: 0.9771 - average_precision: 0.5851 - val_loss: 0.1484 - val_binary_accuracy: 0.9610 - val_average_precision: 0.2322\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 6s 418ms/step - loss: 0.0625 - binary_accuracy: 0.9770 - average_precision: 0.5833 - val_loss: 0.1476 - val_binary_accuracy: 0.9604 - val_average_precision: 0.2311\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "INPUT_SHAPE = [train_df.shape[1]]\n",
    "BATCH_SIZE = 5120\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=INPUT_SHAPE),    \n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_of_labels,activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy', tf.keras.metrics.AUC(multi_label=True, curve='PR', name='average_precision')]\n",
    ")\n",
    "\n",
    "hist = model.fit(\n",
    "    X_train.iloc[:,1:], y_train,\n",
    "    validation_data=(X_val.iloc[:,1:], y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column_1015</th>\n",
       "      <th>Column_1016</th>\n",
       "      <th>Column_1017</th>\n",
       "      <th>Column_1018</th>\n",
       "      <th>Column_1019</th>\n",
       "      <th>Column_1020</th>\n",
       "      <th>Column_1021</th>\n",
       "      <th>Column_1022</th>\n",
       "      <th>Column_1023</th>\n",
       "      <th>Column_1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57275</th>\n",
       "      <td>P23500</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.045471</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>-0.069641</td>\n",
       "      <td>-0.041473</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063416</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>-0.056732</td>\n",
       "      <td>-0.028687</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>-0.038757</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>-0.034424</td>\n",
       "      <td>-0.005363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52450</th>\n",
       "      <td>Q94BP3</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.030441</td>\n",
       "      <td>0.011177</td>\n",
       "      <td>-0.015251</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>-0.009270</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049438</td>\n",
       "      <td>-0.005131</td>\n",
       "      <td>-0.036255</td>\n",
       "      <td>-0.018921</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>-0.034637</td>\n",
       "      <td>-0.038910</td>\n",
       "      <td>0.007427</td>\n",
       "      <td>0.013496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95625</th>\n",
       "      <td>P02315</td>\n",
       "      <td>0.051056</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-0.057098</td>\n",
       "      <td>-0.048828</td>\n",
       "      <td>-0.009148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019196</td>\n",
       "      <td>0.032745</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>-0.081177</td>\n",
       "      <td>-0.008156</td>\n",
       "      <td>-0.020996</td>\n",
       "      <td>-0.029602</td>\n",
       "      <td>0.045105</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.057587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82884</th>\n",
       "      <td>Q06525</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>-0.087769</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>-0.031586</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.080261</td>\n",
       "      <td>-0.009590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>-0.013573</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>-0.088745</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.035980</td>\n",
       "      <td>0.033356</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0.028503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>Q7DA74</td>\n",
       "      <td>0.048859</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.028473</td>\n",
       "      <td>-0.003517</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>-0.032684</td>\n",
       "      <td>-0.060638</td>\n",
       "      <td>0.038696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086853</td>\n",
       "      <td>-0.044769</td>\n",
       "      <td>-0.004410</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.023636</td>\n",
       "      <td>-0.014793</td>\n",
       "      <td>-0.029343</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>-0.007362</td>\n",
       "      <td>0.019119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>Q9NUD9</td>\n",
       "      <td>0.018784</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.042175</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>-0.031525</td>\n",
       "      <td>-0.046387</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>-0.003323</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.046783</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>-0.026703</td>\n",
       "      <td>-0.013672</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79816</th>\n",
       "      <td>Q9W0M7</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.042206</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>-0.019135</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>-0.030472</td>\n",
       "      <td>-0.031647</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023254</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>-0.019287</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.032288</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.004513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112326</th>\n",
       "      <td>P71620</td>\n",
       "      <td>-0.059113</td>\n",
       "      <td>-0.035980</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>-0.006058</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>-0.040802</td>\n",
       "      <td>-0.094666</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>-0.019028</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>-0.084106</td>\n",
       "      <td>-0.029053</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>-0.012566</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>0.071411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Q57XW0</td>\n",
       "      <td>-0.057343</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>-0.013527</td>\n",
       "      <td>0.034576</td>\n",
       "      <td>0.040253</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>-0.088562</td>\n",
       "      <td>0.021774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042542</td>\n",
       "      <td>-0.014931</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>-0.056580</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.037170</td>\n",
       "      <td>0.017471</td>\n",
       "      <td>0.076111</td>\n",
       "      <td>0.005451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22443</th>\n",
       "      <td>P07516</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>-0.046906</td>\n",
       "      <td>0.052490</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.012787</td>\n",
       "      <td>-0.042847</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>-0.047089</td>\n",
       "      <td>-0.057037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062866</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>-0.057037</td>\n",
       "      <td>-0.022293</td>\n",
       "      <td>0.090576</td>\n",
       "      <td>0.015526</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>0.027115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67710 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protein_ID  Column_1  Column_2  Column_3  Column_4  Column_5  Column_6  \\\n",
       "57275      P23500  0.067383  0.030548  0.011909  0.045471 -0.006641  0.045868   \n",
       "52450      Q94BP3  0.031525  0.120117  0.030441  0.011177 -0.015251  0.007626   \n",
       "95625      P02315  0.051056  0.008263  0.076172  0.035522  0.027252  0.106445   \n",
       "82884      Q06525  0.005070 -0.087769 -0.000177  0.012009 -0.031586  0.063477   \n",
       "6587       Q7DA74  0.048859  0.030548  0.028473 -0.003517  0.001398  0.072449   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "8779       Q9NUD9  0.018784  0.037048  0.030228  0.042175  0.011719  0.020966   \n",
       "79816      Q9W0M7  0.018982  0.042206  0.025177  0.014626 -0.019135  0.024353   \n",
       "112326     P71620 -0.059113 -0.035980  0.055695 -0.006058 -0.028595  0.024200   \n",
       "1209       Q57XW0 -0.057343 -0.015625 -0.013527  0.034576  0.040253  0.017014   \n",
       "22443      P07516  0.039154 -0.046906  0.052490  0.046875  0.012787 -0.042847   \n",
       "\n",
       "        Column_7  Column_8  Column_9  ...  Column_1015  Column_1016  \\\n",
       "57275  -0.069641 -0.041473 -0.015045  ...    -0.063416    -0.002037   \n",
       "52450  -0.009270 -0.074280  0.023544  ...    -0.049438    -0.005131   \n",
       "95625  -0.057098 -0.048828 -0.009148  ...    -0.019196     0.032745   \n",
       "82884  -0.005371 -0.080261 -0.009590  ...     0.026810    -0.013573   \n",
       "6587   -0.032684 -0.060638  0.038696  ...    -0.086853    -0.044769   \n",
       "...          ...       ...       ...  ...          ...          ...   \n",
       "8779   -0.031525 -0.046387 -0.000349  ...     0.014015     0.002598   \n",
       "79816  -0.030472 -0.031647  0.053802  ...    -0.023254     0.017014   \n",
       "112326 -0.040802 -0.094666 -0.003313  ...     0.046387    -0.019028   \n",
       "1209    0.001482 -0.088562  0.021774  ...    -0.042542    -0.014931   \n",
       "22443   0.035278 -0.047089 -0.057037  ...    -0.062866    -0.015640   \n",
       "\n",
       "        Column_1017  Column_1018  Column_1019  Column_1020  Column_1021  \\\n",
       "57275     -0.056732    -0.028687     0.029861    -0.021347    -0.038757   \n",
       "52450     -0.036255    -0.018921     0.042023    -0.016327    -0.034637   \n",
       "95625      0.022354    -0.081177    -0.008156    -0.020996    -0.029602   \n",
       "82884      0.019730    -0.088745     0.008553     0.083008     0.035980   \n",
       "6587      -0.004410     0.012207     0.023636    -0.014793    -0.029343   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "8779      -0.003323     0.001747     0.046783     0.005169    -0.026703   \n",
       "79816      0.012650    -0.019287     0.023941    -0.009338     0.023270   \n",
       "112326     0.029236    -0.084106    -0.029053    -0.004059     0.003288   \n",
       "1209       0.013908    -0.056580     0.017578    -0.004860    -0.037170   \n",
       "22443     -0.057037    -0.022293     0.090576     0.015526     0.043945   \n",
       "\n",
       "        Column_1022  Column_1023  Column_1024  \n",
       "57275      0.034363    -0.034424    -0.005363  \n",
       "52450     -0.038910     0.007427     0.013496  \n",
       "95625      0.045105     0.023331     0.057587  \n",
       "82884      0.033356     0.042480     0.028503  \n",
       "6587      -0.018967    -0.007362     0.019119  \n",
       "...             ...          ...          ...  \n",
       "8779      -0.013672    -0.030441    -0.000006  \n",
       "79816      0.032288     0.015869    -0.004513  \n",
       "112326    -0.012566     0.042389     0.071411  \n",
       "1209       0.017471     0.076111     0.005451  \n",
       "22443      0.007786     0.070190     0.027115  \n",
       "\n",
       "[67710 rows x 1025 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67710 entries, 57275 to 22443\n",
      "Columns: 1025 entries, Protein_ID to Column_1024\n",
      "dtypes: float16(1024), object(1)\n",
      "memory usage: 133.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67710 entries, 57275 to 22443\n",
      "Columns: 687 entries, GO:0005575 to GO:0016798\n",
      "dtypes: float64(687)\n",
      "memory usage: 355.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for any object types or anomalies\n",
    "print(pd.DataFrame(X_train).info())\n",
    "print(pd.DataFrame(y_train).info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>aspect</th>\n",
       "      <th>GO_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0110165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0005622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P91124</td>\n",
       "      <td>cellular_component</td>\n",
       "      <td>GO:0043226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277042</th>\n",
       "      <td>P28271</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>GO:0010608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277043</th>\n",
       "      <td>P28271</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>GO:0080090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277044</th>\n",
       "      <td>P28271</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>GO:0006417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277045</th>\n",
       "      <td>P28271</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>GO:0051246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277046</th>\n",
       "      <td>P28271</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>GO:0034248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3357733 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Protein_ID              aspect     GO_term\n",
       "0           P91124  cellular_component  GO:0005575\n",
       "1           P91124  cellular_component  GO:0110165\n",
       "2           P91124  cellular_component  GO:0005737\n",
       "3           P91124  cellular_component  GO:0005622\n",
       "4           P91124  cellular_component  GO:0043226\n",
       "...            ...                 ...         ...\n",
       "4277042     P28271  biological_process  GO:0010608\n",
       "4277043     P28271  biological_process  GO:0080090\n",
       "4277044     P28271  biological_process  GO:0006417\n",
       "4277045     P28271  biological_process  GO:0051246\n",
       "4277046     P28271  biological_process  GO:0034248\n",
       "\n",
       "[3357733 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_train = train_set\n",
    "exp_train = train_set[train_set['Protein_ID'].isin(prot_id_has_cc)] #TAKE ONLY EXAMPLES THAT HAVE CC INFO\n",
    "exp_train = train_set[train_set['aspect'] == 'cellular_component'] # TAKE ONLY CELLULAR COMPONENT INFORMATION; NECESSARY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
